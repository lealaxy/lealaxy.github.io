[{"title":"搭建Docker私有仓库","url":"/2022/Docker私有仓库搭建/","content":"\n# Harbor简介\n![]( https://goharbor.io/img/logos/harbor-horizontal-color.png)\nVMware开源的企业级Registry项目Harbor，以Docker公司开源的registry 为基础，提供了管理UI, 基于角色的访问控制(Role Based Access Control)，AD/LDAP集成、以及审计日志(Audit logging) 等企业用户需求的功能，同时还原生支持中文，主要特点：\n\n* 基于角色的访问控制 - 用户与 Docker 镜像仓库通过“项目”进行组织管理，一个用户可以对多个镜像仓库在同一命名空间（project）里有不同的权限。\n* 镜像复制 - 镜像可以在多个 Registry 实例中复制（同步）。尤其适合于负载均衡，高可用，混合云和多云的场景。\n* 图形化用户界面 - 用户可以通过浏览器来浏览，检索当前 Docker 镜像仓库，管理项目和命名空间。\n* AD/LDAP 支持 - Harbor 可以集成企业内部已有的 AD/LDAP，用于鉴权认证管理。\n* 审计管理 - 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。\n* 国际化 - 已拥有英文、中文、德文、日文和俄文的本地化版本。更多的语言将会添加进来。\n* RESTful API - RESTful API 提供给管理员对于 Harbor 更多的操控, 使得与其它管理软件集成变得更容易。\n* 部署简单 - 提供在线和离线两种安装工具， 也可以安装到 vSphere 平台(OVA 方式)虚拟设备\n\n## Harbor架构\n![Harobr架构图](https://github.com/goharbor/harbor/raw/release-2.0.0/docs/img/architecture/architecture.png)\n\nProxy: Harbor的registry、UI、token services等组件，都处在一个反向代理后边。该代理将来自浏览器、docker clients的请求转发到后端服务上。\n\nRegistry: 负责存储Docker镜像，以及处理Docker push/pull请求。因为Harbor强制要求对镜像的访问做权限控制， 在每一次push/pull请求时，Registry会强制要求客户端从token service那里获得一个有效的token。\n\nCore services: Harbor的核心功能，主要包括如下3个服务:\n1. UI: 作为Registry Webhook, 以图像用户界面的方式辅助用户管理镜像。\n2. WebHook：WebHook是在registry中配置的一种机制， 当registry中镜像发生改变时，就可以通知到Harbor的webhook endpoint。Harbor使用webhook来更新日志、初始化同步job等。\n3. Token 服务：负责根据用户权限给每个docker push/pull命令签发token. Docker 客户端向Regiøstry服务发起的请求,如果不包含token，会被重定向到这里，获得token后再重新向Registry进行请求。\nDatabase：为core services提供数据库服务，负责储存用户权限、审计日志、Docker image分组信息等数据。\n\nJob services: 主要用于镜像复制，本地镜像可以被同步到远程Harbor实例上。\n\nLog collector: 负责收集其他组件的日志到一个地方\n\nharbor-adminserver主要是作为一个后端的配置数据管理，harbor-ui所要操作的所有数据都通过harbor-adminserver这样一个数据配置管理中心来完成。\n\n# Harbor安装\n## 安装Docker\nHarbor各个组件全部基于docker，在安装Harbor之前，需要预先安装docker、docker-compose\n## 下载Harbor安装脚本\n从[https://github.com/goharbor/harbor/releases](https://github.com/goharbor/harbor/releases)仓库中下载Harbor安装脚本，如果目标机器可以连接网络的话，下载在线安装版的就可以。\n## 解压harbor安装包\n```shell\ntar xf harbor-online-installer-{}.tgz\n```\n## 生成SSL自签名证书\nHarbor使用Docker-compose启动，使用Nginx作为反响代理，建议部署在机器的80和443端口上，并且进行SSL自签名，这样的话其他机器下载镜像时就不需要配置docker的信任仓库。\n下面是生成SSL签名的流程，需要在机器上提前安装`openssl`软件包。\n\n把下边代码中所有的IP地址都替换成您自己的IP地址。\n```shell\n# 生成默认 ca\nopenssl genrsa -out ca.key 2048\nopenssl req -x509 -new -nodes -key ca.key -subj \"/CN=192.168.0.8\" -days 5000 -out ca.crt\n\n# 生成证书\nopenssl req -new -sha256 \\\n-key ca.key \\\n-subj \"/C=CN/ST=Beijing/L=Beijing/O=UnitedStack/OU=Devops/CN=192.168.0.8\" \\\n-reqexts SAN \\\n-config <(cat /etc/pki/tls/openssl.cnf \\\n<(printf \"[SAN]\\nsubjectAltName=IP:192.168.0.8\")) \\\n-out ca.csr\n\n# 签名证书\nopenssl x509 -req -days 365000 \\\n-in zchd.csr -CA ca.crt -CAkey ca.key -CAcreateserial \\\n-extfile <(printf \"subjectAltName=IP:192.168.0.8\") \\\n-out ca.pem\n\n```\n如果运行成功，会在当前目录下生成`ca.key`和`ca.pem`两个证书文件，在接下来修改Harbor配置文件的时候需要修改这两个文件路径\n## 修改Harbor配置文件\n重命名`harbor.yml.tmpl`为`harbor.yml`。该配置文件中需要注意的参数如下，其他的保持默认配置即可。\n```yaml\nhostname: 192.168.0.8         //设置访问地址，可以使用ip、域名，不可以设置为127.0.0.1或localhost。默认情况下，harbor使用的端口是80，若使用自定义的端口，除了要改docker-compose.yml文件中的配置外，这里的hostname也要加上自定义的端口，否则在docker login、push时会报错\n#http配置\n# http related config\nhttp:\n# port for http, default is 80. If https enabled, this port will redirect to https port\n  port: 80\n\n#https配置（如不需要可不配置,注释掉）\n# https related config\nhttps:\n# https port for harbor, default is 443\n  port: 443\n  # The path of cert and key files for nginx\n  certificate: /path_to/ca.pem\n  private_key: /path_to/ca.key\n\nharbor_admin_password: Harbor12345         # admin密码\n\n#持久化数据目录\ndata_volume: /opt/application/harbor\n```\n\n# 运行Harbor\n配置完毕之后就可以启动Harbor，运行安装脚本，Harbor就会自动安装。\n```shell\n./install.sh\n```\n# 进入Harbor\n之后访问Harbor的WEB页面，默认用户名为`admin`，密码为`Harbor12345`\n","tags":["Docker","DockerHub"],"categories":["Docker","DockerHub"]},{"title":"「docker」构建CUDA镜像","url":"/2022/[docker]构建CUDA镜像/","content":"\n# 背景\n\n实验室的服务器内核版本太老了，有一个项目需要升级内核，但是服务器上还有一堆东西不敢随便升级。\n\n于是就准备用docker构建一个镜像，安装CUDA和Python环境，平时ssh连进去炼丹\n\n# 需求\n\n炼丹必备的cuda肯定是必不可少的，ssh服务器也需要配置，既然准备写一个dockerfile，那python环境和换源之类的也就一块打包到镜像里去得了。\n\n以后谁想炼丹直接新建一个容器，映射好端口之后容器里炼丹的基础设施就都有了。\n\n# 安装\n\n## 宿主机安装CUDA驱动\n\n想要容器能用CUDA，宿主机肯定要安装CUDA驱动，这部分就不讲了，好多博客都有。\n\n## 宿主机安装NVIDIA-CONTAINER-RUNTIME\n\n在[https://nvidia.github.io/nvidia-container-runtime/](https://nvidia.github.io/nvidia-container-runtime/) 查看支持的操作系统和版本，并根据对应选项，添加源，因为我是centos7，所以添加方式为：\n\n```shell\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID)\ncurl -s -L https://nvidia.github.io/nvidia-container-runtime/$distribution/nvidia-container-runtime.repo | \\\nsudo tee /etc/yum.repos.d/nvidia-container-runtime.repo\n```\n\n然后直接`yum install` 就可以安装docker cuda驱动\n\n```shell\nsudo yum install nvidia-container-runtime\n```\n\n进行测试，如果能成功出现显卡信息就可以了\n\n```shell\ndocker run -it --rm --gpus all centos nvidia-smi\n```\n\n## 构建Dockerfile\n\n直接把`Dockerfile`复制过去，build一下就完事了，可能需要根据自己的CUDA版本换一下第一行的`FROM`部分，具体根据[https://hub.docker.com/r/nvidia/cuda/tags](https://hub.docker.com/r/nvidia/cuda/tags)换一下版本号（如果不想安装ubuntu版本的那下边的`RUN apt install`命令都不能执行。\n\n我这里给这个镜像换了阿里源，安装了显示图形界面必备的一些包，打开了ssh-server并设置初始密码为123456。这样镜像跑起来之后就可以直接用ssh连了，不需要`exec`进容器里再设置密码之类的，方便管理员批量创建。\n\n```dockerfile\nFROM nvidia/cuda:11.4.2-cudnn8-devel-ubuntu18.04\nLABEL author=\"li.yunhao@foxmail.com\"\n\nENV PASSWORD=\"123456\" \n\nRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime && echo 'Asia/Shanghai' >/etc/timezone \\\n    && sed -i \"s/archive.ubuntu.com/mirrors.aliyun.com/g\" /etc/apt/sources.list \\\n    && sed -i \"s/security.ubuntu.com/mirrors.aliyun.com/g\" /etc/apt/sources.list \\\n    && apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub \\\n    && apt clean && apt update && apt install -yq --no-install-recommends sudo \\\n    && sudo apt install -yq --no-install-recommends python3 python3-pip libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev openssh-server \\\n    && sudo pip3 install --upgrade pip \\\n    && sudo pip3 config set global.index-url https://mirrors.aliyun.com/pypi/simple \\\n    && sudo pip3 install setuptools \\\n    && sed -i \"s/#PubkeyAuthentication/PubkeyAuthentication/g\" /etc/ssh/sshd_config \\\n    && sed -i \"s/#AuthorizedKeysFile/AuthorizedKeysFile/g\" /etc/ssh/sshd_config \\\n    && sed -i \"s/#PermitRootLogin prohibit-password/PermitRootLogin yes/g\" /etc/ssh/sshd_config \\\n    && sudo /etc/init.d/ssh restart \\\n    && echo \"root:${PASSWORD}\" | chpasswd\nENTRYPOINT /etc/init.d/ssh restart && /bin/bash\n\n```\n\n## 运行容器\n\n把`Dockerfile`写好之后就可以build了\n\n```shell\nsudo docker build -t cuda:11.4.2-cudnn8-ubuntu18-py36 .\n```\n\n在启动docker容器的时候要注意加一些cuda的参数\n\n* `-p`是映射端口，我这里把22端口映射出来供ssh使用\n* `--gpus all`和`-e NVIDIA_VISIBLE_DEVICES=all`选择这个容器可见的显卡，直接全部就完事了\n* `-e NVIDIA_DRIVER_CAPABILITIES=compute,utility`配置了一些cuda必备的包如nvidia-smi之类的\n\n```shell\nsudo docker run -itd -p 43251:22 --gpus all --name cuda -e NVIDIA_DRIVER_CAPABILITIES=compute,utility -e NVIDIA_VISIBLE_DEVICES=all cuda:11.4.2-cudnn8-ubuntu18-py36\n```\n\n运行容器之后就可以愉快的ssh连进去炼丹了，再也不用担心环境搞崩影响其他人了。\n\n# PyTorch版本\n\n上边那个镜像构建出来的容器啥都没有，conda之类的还需要自己安装。于是我又写了一份Pytorch版本的`Dockerfile`，这里边conda已经默认安装好并且换好阿里源了，可以说是开箱即用。\n\n我这边已经上传到Docker Hub一份镜像，直接pull下来就可以用\n\n```shell\ndocker pull lealaxy/pytorch:1.11-cuda11.3-cudnn8\ndocker run -itd -p 43251:22 -p 14380:80 --gpus all --name pytorch -e NVIDIA_VISIBLE_DEVICES=all lealaxy/pytorch:1.11-cuda11.3-cudnn8\n```\n\n\n\n```dockerfile\nFROM pytorch/pytorch:1.11.0-cuda11.3-cudnn8-runtime\nLABEL author=\"li.yunhao@foxmail.com\"\n\nENV PASSWORD=\"123456\" \n\nRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime && echo 'Asia/Shanghai' >/etc/timezone \\\n    && sed -i \"s/archive.ubuntu.com/mirrors.aliyun.com/g\" /etc/apt/sources.list && sed -i \"s/security.ubuntu.com/mirrors.aliyun.com/g\" /etc/apt/sources.list \\\n    && apt clean && apt update && apt install -yq gnupg \\\n    && apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub \\\n    && conda config --set show_channel_urls yes && conda init\\\n    && echo \"channels:\" >>  ~/.condarc && echo \"  - defaults\" >>  ~/.condarc && echo \"default_channels:\" >>  ~/.condarc && echo \"  - http://mirrors.aliyun.com/anaconda/pkgs/main\" >>  ~/.condarc && echo \"  - http://mirrors.aliyun.com/anaconda/pkgs/r\" >>  ~/.condarc && echo \"  - http://mirrors.aliyun.com/anaconda/pkgs/msys2\" >>  ~/.condarc && echo \"custom_channels:\" >>  ~/.condarc && echo \"  conda-forge: http://mirrors.aliyun.com/anaconda/cloud\" >>  ~/.condarc && echo \"  msys2: http://mirrors.aliyun.com/anaconda/cloud\" >>  ~/.condarc && echo \"  bioconda: http://mirrors.aliyun.com/anaconda/cloud\" >>  ~/.condarc && echo \"  menpo: http://mirrors.aliyun.com/anaconda/cloud\" >>  ~/.condarc && echo \"  pytorch: http://mirrors.aliyun.com/anaconda/cloud\" >>  ~/.condarc && echo \"  simpleitk: http://mirrors.aliyun.com/anaconda/cloud\" >>  ~/.condarc \\\n    && apt clean && apt update && apt install -yq --no-install-recommends sudo \\\n    && apt install -yq --no-install-recommends libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev openssh-server git wget curl vim\\\n    && pip install --upgrade pip && pip config set global.index-url https://mirrors.aliyun.com/pypi/simple && pip install setuptools \\\n    && sed -i \"s/#PubkeyAuthentication/PubkeyAuthentication/g\" /etc/ssh/sshd_config && sed -i \"s/#AuthorizedKeysFile/AuthorizedKeysFile/g\" /etc/ssh/sshd_config && sed -i \"s/#PermitRootLogin prohibit-password/PermitRootLogin yes/g\" /etc/ssh/sshd_config \\\n    && echo \"root:${PASSWORD}\" | chpasswd \\\n    && conda init\nRUN yes | unminimize\nENTRYPOINT /bin/bash\n\n```\n\n","tags":["Docker","Dockerfile"],"categories":["Docker","Dockerfile"]},{"title":"「深度学习基础」余弦退火学习率-PyTorch版","url":"/2022/[深度学习基础]余弦退火学习率/","content":"\n## 模型训练Trick\n\n**背景：**深层神经网络难训练是因为学习过程**容易陷入到马鞍面**中，即在坡面上，一部分点是上升的，一部分点是下降的，如图在z轴上是最小值，而在x轴上是最大值。马鞍面上损失对参数的一阶导数为0，二阶导数的正负值不相同，由于梯度为0，模型无法进一步更新参数，因此模型训练容易陷入马鞍面中不再更新。\n\n![image-20220429184556646](https://img.peterli.club/img/image-20220429184556646.png)\n\n而余弦退火学习率可以很好的改善这个问题，这个是[Pytorch官方的介绍](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html)。\n\n但是官方的介绍里只有公式，没有告诉我们如何使用。\n\n公式看不懂的同学不用担心，PyTorch都给我们封装好了，使用起来非常简单，PyTorch自带两个余弦学习率调整的方法，一个是CosineAnnealingLR，另一个是CosineAnnealingWarmRestarts。\n\n## CosineAnnealingLR\n\n```python\nCosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1, verbose=False):\n```\n\n\n\n这个比较简单，只对其中的最关键的T*max参数作一个说明,这个可以理解为余弦函数的半周期.如果max*_epoch=50次，那么设置T_max=5则会让学习率余弦周期性变化5次。学习率图像大概长成这样：\n\n![image-20220429191710354](https://img.peterli.club/img/image-20220429191710354.png)\n\n## CosineAnnealings\n\n```python\nCosineAnnealingWarmRestarts(optimizer, T_0, T_mult=1, eta_min=0, last_epoch=-1, verbose=False):\n```\n\n\n\n这个是带热重启的学习率,这个最主要的参数有两个:\n\n- T_0:学习率第一次回到初始值的epoch位置\n\n- T_mult:这个控制了学习率变化的速度\n\n- - 如果T_mult=1,则学习率在T_0,2*T_0,3*T_0,....,i*T_0,....处回到最大值(初始学习率)\n\n  - - 5,10,15,20,25,.......处回到最大值\n\n  - 如果T_mult>1,则学习率在T_0,(1+T_mult)*T_0,(1+T_mult+T_mult**2)*T_0,.....,(1+T_mult+T_mult**2+...+T_0**i)*T0,处回到最大值\n\n  - - 5,15,35,75,155,.......处回到最大值\n\n这个的图像大概长成下边这样，根据设定的参数不同具体数值会有所区别。\n\n![image-20220429184820914](http://img.peterli.club/img/image-20220429184820914.png)\n\n所以可以看到，在调节参数的时候，一定要根据自己总的epoch合理的设置参数，不然很可能达不到预期的效果,经过我自己的试验发现，如果是用那种等间隔的退火策略(CosineAnnealingLR和T*mult=1的CosineAnnealingWarmRestarts)，验证准确率总是会在学习率的最低点达到一个很好的效果，而随着学习率回升，验证精度会有所下降.所以为了能最终得到一个更好的收敛点，设置T_mult>1是很有必要的，这样到了训练后期，学习率不会再有一个回升的过程,而且一直下降直到训练结束。\n\n## 示例代码\n\n余弦学习率使用起来非常简单，只需要在每一个epoch的training和validation之后加上`scheduler.step()`就可以完成学习率的调整\n\n```python\nimport torch.optim.lr_scheduler as lr_scheduler\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5) # 这里可以随便换optimizer\n# 定义一个scheduler 参数自己设置\nscheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-5)\n# 如果想用带热重启的，可以向下面这样设置\nscheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=10, eta_min=1e-5)\nfor epoch in range(num_epochs):\n    training() # 训练\n    validation() # 测试\n    scheduler.step() # 这是关键代码，在每一个epoch最后加上这一行，就可以完成学习率的调整\n```\n\n## 总结\n\n余弦学习率理解起来非常简单，用起来也是很方便。\n\n用李宏毅老师的话，这都是**古圣先贤的意思，用就对了**。大杀器啊，以后训练模型可能都会选择用一下。\n\n我的理解是使用余弦退火的时候可以很直观的看到哪些学习率是比较合适的，这对我们选择正确的学习率参数很有帮助，可以逃离局部最优值。\n","tags":["Machine learning","Learning Rate"],"categories":["Machine learning","PyTorch"]},{"title":"ubuntu下回退内核版本","url":"/2021/ubuntu下回退内核版本/","content":"\n查看可用内核信息\n----------------\n\n`grep menuentry /boot/grub/grub.cfg`\n\n安装回退版本的内核\n------------------\n\n***x.x.x-x为内核版本,本文以4.18.0-18为例***\n`sudo apt-get install linux-headers-x.x.x-x-generic linux-image-x.x.x-x-generic`\n\n安装4.18.0-18版本内核\n---------------------\n\n`sudo apt-get install linux-headers-4.18.0-18-generic linux-image-4.18.0-18-generic`\n\n修改GRUB\n--------\n\n`sudo gedit /etc/default/grub`\n将`GRUB_DEFAULT=0`修改为你所想要还原的版本号，\n如：`GRUB_DEFAULT=\"Advanced options for Ubuntu > Ubuntu, with Linux 4.18.0-18-generic\"`\n\n更新GRUB\n--------\n\n`sudo update-grub` ***然后重启电脑*** 使用`uname -r`查看内核版本","tags":["Linux","Kernel","Ubuntu"],"categories":["Linux"]},{"title":"docker笔记","url":"/2021/docker笔记/","content":"# 笔记\n## 常用命令\n\n```shell\nattach    # 当前shell下attach连接指定运行镜像\nbuild     # 通过Dockerfile定制镜像\ncommit    # 提交当前容器为新的镜像\ncp        # 从容器中拷贝指定文件或目录到宿主机中\ncreate    # 创建一个新的容器，同 run 但不启动容器\ndiff      # 查看 docker 容器变化\nevents    # 从docker服务器获取容器实时事件\nexec      # 在已存在的容器上运行命令\nexport    # 导出容器的内容流作为一个 tar 归档文件【对应 import】\nhistory   # 展示一个镜像形成历史\nimages    # 列出系统当前镜像\nimport    # 从tar包中的内容创建一个新的文件系统映像【对应 export】\ninfo      # 显示系统相关信息\ninspect   # 查看容器详细信息\nkill      # kill 指定的容器\nload      # 从一个 tar 包中加载一个镜像【对应 save】\nlogin     # 注册或者登录一个 docker 源服务器\nlogout    # 从当前 Docekr registry 退出\nlogs      # 输出当前容器日志信息\n```\n\n![](https://img.peterli.club/img/20201121102110.png)\n\n### 安装docker\n\n```shell\nsudo yum install docker -y\nsudo mkdir -p /etc/docker\n# 配置镜像顺便打开远程连接\nsudo tee /etc/docker/daemon.json <<-'EOF'\n{\n  \"registry-mirrors\": [\"https://wlwugsdq.mirror.aliyuncs.com\"],\n  \"hosts\":[\n    \"unix:///var/run/docker.sock\",\n    \"tcp://0.0.0.0:2375\"\n  ]\n}\nEOF\nsudo systemctl daemon-reload\nsudo systemctl restart docker\nsystemctl enable docker\n# 打开防火墙\niptables -I INPUT -ptcp --dport 2375 -j ACCEPT\n```\n\n\n\n### 重启\n\n```bash\nsudo service docker restart\n```\n\n### 自动重启容器\n\n```shell\ndocker container update --restart=always 容器名\n```\n\n### 查看CPU状态\n\n```shell\ndocker stats\n```\n\n### 查看容器详情\n\n```shell\ndocker inspect id\n```\n\n### 本地卷\n\n```shell\ndocker volume\n```\n\n## Dockerfile\n\n![image-20201121102819378](https://img.peterli.club/img/image-20201121102819378.png)\n\n### 构建Dockerfile\n\n```dockerfile\n# Dockerfile\nFROM centos\nMAINTAINER peter<295741554@qq.com>\n\nENV MYPATH /usr/local\nWORKDIR $MYPATH\n\nRUN yum install -y vim\nRUN yum install -y net-tools\n\nEXPOSE 80\nCMD echo $MYPATH\nCMD echo \"-----end----\"\nCMD /bin/bash\n\n# build 构建\n# docker build -f centos-dockerfile -t mycentos:0.1 .\n\n# ENTRYPOINT 命令行追加命令，直接追加在ENTRYPOINT后面\n```\n\n## Docker网络\n\n### `Docker0`\n\n![image-20201122091322470](https://img.peterli.club/img/image-20201122091322470.png)\n\n```shell\n# 启动tomcat \ndocker run -d -p 8080:8080 --name tomcat01 tomcat\n# 查看容器内部IP地址\ndocker exec -it tomcat01 ip addr\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n26: eth0@if27: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default\n    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 172.17.0.3/16 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:acff:fe11:3/64 scope link\n       valid_lft forever preferred_lft forever\n# docker可以ping通容器内部\n```\n\n> 原理\n\n1. 每启动一个docker容器，docker就会给容器分配一个ip。安装docker，就会有一个网卡`docker0`，桥接模式，使用`veth-pair`技术\n\n2. 启动一个容器，就会多出一对网卡。`veth-pair`就是一对虚拟设备接口，是成对出现的，一端连着协议，一端彼此相连。充当桥梁，连接虚拟网络设备。\n\n3. 容器之间也可以相互ping通\n\n   **所有容器不指定网络的情况下，都是由`docker0`路由的，docker为容器分配一个默认可用IP**\n\n![image-20201122094418844](http://img.peterli.club/img/image-20201122094418844.png)\n\n### --link(废弃)\n\n   ```shell\ndocker run -d -P --name tomcat03 --link tomcat02 tomcat\n\n# 通过--link可以通过容器名连接网络\ndocker exec -it tomcat03 ping tomcat02\nPING tomcat02 (172.17.0.4) 56(84) bytes of data.\n64 bytes from tomcat02 (172.17.0.4): icmp_seq=1 ttl=64 time=0.143 ms\n64 bytes from tomcat02 (172.17.0.4): icmp_seq=2 ttl=64 time=0.051 ms\n   ```\n\n--link是再hosts配置中增加了映射\n\n```shell\n$ docker exec -it tomcat03 cat /etc/hosts\n127.0.0.1       localhost\n::1     localhost ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\n172.17.0.4      tomcat02 18a73f07b1c1\n172.17.0.5      40cd4cbf4e21\n```\n\n### 自定义网络\n\n![image-20201122100414348](https://img.peterli.club/img/image-20201122100414348.png)\n\n> 网络模式\n>\n> 1. bridge： 桥接模式\n> 2. none：不配置网络\n> 3. host： 和宿主机共享网络\n> 4. container： 容器内网络连通\n\n```shell\n# 创建docker网络\ndocker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet\n \ndocker network ls\nNETWORK ID          NAME                DRIVER              SCOPE\nb50d910e8c6c        bridge              bridge              local\n6463e6f691bd        host                host                local\n3f8195ef9212        mynet               bridge              local\neaf98583bff5        none                null                local\n\n# 查看网络\n$ docker network inspect mynet\n[\n    {\n        \"Name\": \"mynet\",\n        \"Id\": \"3f8195ef9212df0b92788e50fae3fe9dbb9e1804cad22177c12563dc7398dd06\",\n        \"Created\": \"2020-11-22T10:11:47.121577758+08:00\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": {},\n            \"Config\": [\n                {\n                    \"Subnet\": \"192.168.0.0/16\",\n                    \"Gateway\": \"192.168.0.1\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Attachable\": false,\n        \"Containers\": {\n            \"36e54ef8ed34073451370465936861314a61a74043952e4a31a46828fff4b903\": {\n                \"Name\": \"tomcat01-net\",\n                \"EndpointID\": \"0103650ff1854283537d6ed45abf3544fab69a970d8a890dc954c9c1a3841910\",\n                \"MacAddress\": \"02:42:c0:a8:00:02\",\n                \"IPv4Address\": \"192.168.0.2/16\",\n                \"IPv6Address\": \"\"\n            },\n            \"62e486ac7f1dfb06993a94c1c934be376772e4c7b108f74dbe4474addfb67b1e\": {\n                \"Name\": \"tomcat02-net\",\n                \"EndpointID\": \"89911b659cecd661a6605d433c46a65e9b43a96c92f7e9f1dd74c336c6611927\",\n                \"MacAddress\": \"02:42:c0:a8:00:03\",\n                \"IPv4Address\": \"192.168.0.3/16\",\n                \"IPv6Address\": \"\"\n            }\n        },\n        \"Options\": {},\n        \"Labels\": {}\n    }\n]\n\n# 不使用--link也可以ping容器名\n$ docker exec -it tomcat01-net  ping tomcat02-net\nPING tomcat02-net (192.168.0.3) 56(84) bytes of data.\n64 bytes from tomcat02-net.mynet (192.168.0.3): icmp_seq=1 ttl=64 time=0.052 ms\n64 bytes from tomcat02-net.mynet (192.168.0.3): icmp_seq=2 ttl=64 time=0.049 ms\n^C\n--- tomcat02-net ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 2ms\nrtt min/avg/max/mdev = 0.049/0.050/0.052/0.007 ms\n```\n\n不同集群使用不同网络，保证集群健康\n\n**自定义网络功能齐全，推荐使用自定义网络**\n\n### 网络连通\n\n```shell\n# 网络连通\n$ docker network connect --help\n\nUsage:  docker network connect [OPTIONS] NETWORK CONTAINER\n\nConnect a container to a network\n\nOptions:\n      --alias stringSlice           Add network-scoped alias for the container\n      --help                        Print usage\n      --ip string                   IP Address\n      --ip6 string                  IPv6 Address\n      --link list                   Add link to another container (default [])\n      --link-local-ip stringSlice   Add a link-local address for the container\n```\n\n![image-20201122103256321](https://img.peterli.club/img/image-20201122103256321.png)\n\n```shell\n# 连通tomcat01 与 mynet\ndocker network connect mynet tomcat01\n# 一个容器，两个IP\n\n# 连通之后，就可以ping通\n$ docker exec -it tomcat01 ping tomcat01-net\nPING tomcat01-net (192.168.0.2) 56(84) bytes of data.\n64 bytes from tomcat01-net.mynet (192.168.0.2): icmp_seq=1 ttl=64 time=0.088 ms\n64 bytes from tomcat01-net.mynet (192.168.0.2): icmp_seq=2 ttl=64 time=0.054 ms\n^C\n--- tomcat01-net ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 999ms\nrtt min/avg/max/mdev = 0.054/0.071/0.088/0.017 ms\n```\n\n### 部署Redis集群\n\n![image-20201122103804310](https://img.peterli.club/img/image-20201122103804310.png)\n\n```shell\n# 创建网卡\ndocker network create redis --subnet 172.38.0.0/16\n# 批量创建redis脚本\nfor port in $(seq 1 6); \\\ndo \\\nmkdir -p /mydata/redis/node-${port}/conf\ntouch /mydata/redis/node-${port}/conf/redis.conf\ncat << EOF >/mydata/redis/node-${port}/conf/redis.conf\nport 6379 \nbind 0.0.0.0\ncluster-enabled yes \ncluster-config-file nodes.conf\ncluster-node-timeout 5000\ncluster-announce-ip 172.38.0.1${port}\ncluster-announce-port 6379\ncluster-announce-bus-port 16379\nappendonly yes\nEOF\ndone\n# 启动reids\nfor port in $(seq 1 6); \\\ndo \\\ndocker run -p 637${port}:6379 -p 1637${port}:16379 --privileged=true --name redis-${port} \\\n    -v /mydata/redis/node-${port}/data:/data \\\n    -v /mydata/redis/node-${port}/conf/redis.conf:/etc/redis/redis.conf \\\n    -d --net redis --ip 172.38.0.1${port} redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf\ndone\n\n# 配置集群\nredis-cli --cluster create 172.38.0.11:6379 172.38.0.12:6379 172.38.0.13:6379 172.38.0.13:6379 172.38.0.14:6379 172.38.0.15:6379 172.38.0.16:6379 --cluster-replicas 1\n# 连接集群\nredis-cli -c\n```\n\n## Docker Compose\n\n> 管理多个容器和依赖关系\n\nCompose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application’s services. Then, with a single command, you create and start all the services from your configuration. To learn more about all the features of Compose, see [the list of features](https://docs.docker.com/compose/#features).\n\nCompose works in all environments: production, staging, development, testing, as well as CI workflows. You can learn more about each case in [Common Use Cases](https://docs.docker.com/compose/#common-use-cases).\n\n三步骤：\n\nUsing Compose is basically a three-step process: \n\n1. Define your app’s environment with a `Dockerfile` so it can be reproduced anywhere.\n2. Define the services that make up your app in `docker-compose.yml` so they can be run together in an isolated environment.\n3. Run `docker-compose up` and Compose starts and runs your entire app.\n\n### 安装\n\n```shell\ncurl -L https://get.daocloud.io/docker/compose/releases/download/1.25.5/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose\ndocker-compose --version\n```\n\n### 启动服务\n\n![image-20201123172844845](https://img.peterli.club/img/image-20201123172844845.png)\n\n## Docker Swarm\n\n\n\n# 端口表\n\n## 80 Jenkins\n\n### 安装\n\n```shell\ndocker pull jenkins/jenkins\n```\n\n### 启动\n\n```shell\ndocker run -d -p 80:8080 -p 50000:50000 -v /var/jenkins_home -v /etc/localtime:/etc/localtime --name jenkins docker.io/jenkins/jenkins\n```\n\n### 获取初始密码\n\n```shell\ndocker exec jenkins tail /var/jenkins_home/secrets/initialAdminPassword\n```\n\n\n\n## 3306 MySQL\n\n### 安装\n\n```bash\ndocker pull mysql\n```\n\n### 运行\n\n```bash\ndocker run -di --name=mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=admin mysql\n```\n\n\n## 5671、5672 、15672 RabbitMQ\n\n### 安装\n\n```sh\ndocker pull rabbitmq:management\n```\n\n### 运行\n\n```sh\ndocker run -id --name=rabbitmq -p 5671:5671 -p 5672:5672 -p 4369:4369 -p 15672:15672 -p 25672:25672 rabbitmq:management\n```\n\n## 9000 portainer\n\n### 安装\n\n```shell\ndocker pull portainer/portainer\n```\n\n### 运行\n\n```shell\ndocker run -it -d --name portainer -p 9000:9000 --restart=always --privileged=true -v /var/run/docker.sock:/var/run/docker.sock  portainer/portainer\n```\n\n\n\n## 9200、9300 elasticsearch\n\n### 集群\n\n```yml\nversion: \"3.1\"\nservices:\n  elasticsearch:\n    image: elasticsearch:6.8.11\n    restart: always\n    container_name: elasticsearch\n    environment:\n      - cluster.name=docker-cluster\n      - bootstrap.memory_lock=true\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n    volumes:\n      - ./esdata:/usr/share/elasticsearch/data\n    ports:\n      - 9200:9200\n  kibana:\n    image: kibana:6.8.11\n    restart: always\n    container_name: kibana\n    ports:\n      - 5601:5601\n    environment:\n        # 这里记得修改为你的服务器ip\n      - elasticsearch_url=http://192.168.111.134:9200\n    depends_on:\n      - elasticsearch\n      \nvolumes:\n  esdata:\n    driver: local\n\n```\n\n### docker安装常见Bug\n\n- elasticsearch用docker启动一会之后服务自动关闭的问题\n\n  分配内存太小，需要将vm.max_map_count的值调大，网上查资料，得知用命令的方式来设置vm.max_map_count，命令如下：\n\n  ```\n  sysctl -w vm.max_map_count=2621441\n  ```\n\n  查看vm.max_map_count命令：\n\n  ```\n  sysctl -a|grep vm.max_map_count\n  ```\n\n但是以上方法在重启虚拟机之后就不生效，如果想要一直生效的话，到 /etc目录下编辑sysctl.conf文件，添加vm.max_map_count=262144就可以了。\n 保存文件之后用sysctl -a|grep vm.max_map_count命令查看，显示的还是修改之前的值，**此时需要重启虚拟机才能生效**\n\n- docker 启动 elasticsearch 异常 Failed to create node environment\n\n  chmod 777 挂载目录路径\n\n### 安装中文分词器\n\n```bash\ndocker exec -it elasticsearch bash\n# 去github上下载对应版本的ik(zip)\ncd /usr/share/elasticsearch/bin/\n./elasticsearch-plugin install http://39.97.240.81/resource/elasticsearch-analysis-ik-6.8.11.zip\n```\n\n之后重启elasticsearch容器（记住是重启，不是down掉再up!!!)\n\n```\ndocker restart elasticsearch\n```","tags":["Docker"],"categories":["Docker"]},{"title":"Docker Caffe训练自定义模型","url":"/2020/Docker-Caffe训练自定义模型/","content":"## docker安装caffe\n\ndocker构建容器，新建文件Dockerfile，复制进下面的内容，然后运行build构建容器，读条完毕后CPU版的docker Caffe就安装好了。\n\n```bash\ndocker build -t caffe:1.0 .\n```\n\n### Dockerfile\n\n```dockerfile\nFROM ubuntu:16.04\nLABEL maintainer caffe-maint@googlegroups.com\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n        build-essential \\\n        cmake \\\n        git \\\n        wget \\\n        libatlas-base-dev \\\n        libboost-all-dev \\\n        libgflags-dev \\\n        libgoogle-glog-dev \\\n        libhdf5-serial-dev \\\n        libleveldb-dev \\\n        liblmdb-dev \\\n        libopencv-dev \\\n        libprotobuf-dev \\\n        libsnappy-dev \\\n        protobuf-compiler \\\n        python-dev \\\n        python-numpy \\\n        python-pip \\\n        python-setuptools \\\n        python-scipy && \\\n    rm -rf /var/lib/apt/lists/*\n\nENV CAFFE_ROOT=/opt/caffe\nWORKDIR $CAFFE_ROOT\n\n# FIXME: use ARG instead of ENV once DockerHub supports this\n# https://github.com/docker/hub-feedback/issues/460\nENV CLONE_TAG=1.0\n\nRUN git clone -b ${CLONE_TAG} --depth 1 https://gitee.com/mirrors/caffe.git . && \\\n    pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -U && \\\n    pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple && \\\n    cd python && for req in $(cat requirements.txt) pydot; do pip install $req; done && cd .. && \\\n    mkdir build && cd build && \\\n    cmake -DCPU_ONLY=1 .. && \\\n    make -j\"$(nproc)\"\n\nENV PYCAFFE_ROOT $CAFFE_ROOT/python\nENV PYTHONPATH $PYCAFFE_ROOT:$PYTHONPATH\nENV PATH $CAFFE_ROOT/build/tools:$PYCAFFE_ROOT:$PATH\nRUN echo \"$CAFFE_ROOT/build/lib\" >> /etc/ld.so.conf.d/caffe.conf && ldconfig\n\nWORKDIR /workspace\n\n```\n\n## 样本分类和转化样本数据\n\n运行python脚本，把样本数据装化成caffe可以识别的格式。\n\n注意样本数据名称不能有空格如果有空格的话，需要运行下边这个脚本给样本批量重命名。\n\n```bat\n@echo off&setlocal EnableDelayedExpansion \nset a=1 \nfor /f \"delims=\" %%i in ('dir /b *.bmp') do ( \nif not \"%%~ni\"==\"%~n0\" ( \nif !a! LSS 10 (ren \"%%i\" \"!a!.bmp\") else ren \"%%i\" \"!a!.bmp\" \nset/a a+=1 \n) \n)\n\n```\n\n![样本结构](https://img.peterli.club/img/20200830201247.png)\n\n\n\n### 样本分类脚本\n\n```python\n# -*- coding: UTF-8 -*-\nimport os\nimport random\n\nimage_path = '../trainImages'  # \"train文件夹的路径\"\ntxt_path = '../'  # \"生成txt文件夹的路径\"\n\nif __name__ == '__main__':\n    # 将数据分成训练集，测试集和验证集\n    val_percent = 0.2\n    train_percent = 0.8\n\n    labels = os.listdir(image_path)\n\n    image_list = [os.path.join(root, fn) for root, dirs, files in os.walk(image_path) for fn in files]\n    image_count = len(image_list)\n\n    list = range(image_count)\n    tv = int(image_count * val_percent)\n    tr = int(image_count * train_percent)\n    val = random.sample(list, tv)\n\n    # 创建文件\n    file_train = open(txt_path + '/train.txt', 'wt')\n    file_val = open(txt_path + '/val.txt', 'wt')\n\n    # 遍历生成文件内容\n    for i in list:\n        # 解析文件标签\n        name = image_list[i]\n        sub_name = name[:name.rindex(\"\\\\\")]\n        file_name = name[name.rindex(\"\\\\\") + 1:]\n        label = sub_name[sub_name.rindex(\"\\\\\") + 1:]\n        index = labels.index(label)\n        if i in val:\n            print('样本 (' + name + ') 标签 (' + str(index) + ') 标为验证集')\n            file_val.write(label + '/' + file_name + ' ' + str(index) + '\\n')\n        else:\n            print('样本 (' + name + ') 标签 (' + str(index) + ') 标为训练集')\n            file_train.write(label + '/' + file_name + ' ' + str(index) + '\\n')\n\n    file_train.close()\n    file_val.close()\n    print('完成！')\n\n    print('标签种类:')\n    print(labels)\n\n    print('样本总数:' + str(image_count))\n    print('训练集总数:' + str(tr))\n    print('验证集总数:' + str(tv))\n    exit(1)\n\n```\n\n生成完txt后，txt里的数据应该是这个样的。\n\n![2019-12-14s22-22-21屏幕截图.png](https://i.loli.net/2019/12/14/GjP5XkZ2vgNSQa7.png)\n\n工程结构是这个样的\n\n![](https://img.peterli.club/img/20200830201449.png)\n\n## 开始训练\n\n创建生成好的容器\n\n```bash\ndocker run -id --name caffe caffe:1.0\n```\n\n\n\n输入下边脚本进入容器，并把整个工程复制到初始的`/workspace`目录下。\n\n```bash\nsudo docker exec -it 容器号 /bin/bash\n```\n\n```bash\ndocker cp 本地文件的路径 container_id:<docker容器内的路径>\n```\n\n### 模型文件\n\n模型都放在工程目录下的`model`文件夹里\n\n**solver.prototxt**\n\n```\nnet: \"/workspace/Caffe/model/train_val.prototxt\" #这里时train_val.prototxt文件的路径\ntest_iter: 4                # x * 50 = 训练集大小\ntest_interval: 50\nbase_lr: 0.01\nlr_policy: \"step\"\ngamma: 0.1\nstepsize: 100\ndisplay: 20\nmax_iter: 1000              #最大训练次数\nmomentum: 0.9\nweight_decay: 0.0005\nsnapshot: 100                #每x次保存一次模型快照\nsnapshot_prefix: \"/workspace/Caffe/save_model/\" #生成快照的路径\nsolver_mode: CPU\n```\n\n\n\n**train_val.prototxt**\n\n```prototxt\nname: \"LeNet\"\nlayer {\n  name: \"mnist\"\n  type: \"Data\"\n  top: \"data\"\n  top: \"label\"\n  include {\n    phase: TRAIN\n  }\n  transform_param {\n    mirror: true\n    crop_size: 20\n    mean_file: \"/workspace/Caffe/train_mean.binaryproto\"\n  }\n  data_param {\n    source: \"/workspace/Caffe/train_lmdb\"\n    batch_size: 32\n    backend: LMDB\n  }\n}\nlayer {\n  name: \"mnist\"\n  type: \"Data\"\n  top: \"data\"\n  top: \"label\"\n  include {\n    phase: TEST\t\t\n  }\n  transform_param {\n    mirror: false\n    crop_size: 20\n    mean_file: \"/workspace/Caffe/val_mean.binaryproto\"\n  }\n  data_param {\n    source: \"/workspace/Caffe/val_lmdb\"\n    batch_size: 50\n    backend: LMDB\n  }\n}\nlayer {\n  name: \"conv1\"\n  type: \"Convolution\"\n  bottom: \"data\"\n  top: \"conv1\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  convolution_param {\n    num_output: 20\n    kernel_size: 5\n    stride: 1\n    weight_filler {\n      type: \"xavier\"\n    }\n    bias_filler {\n      type: \"constant\"\n    }\n  }\n}\nlayer {\n  name: \"pool1\"\n  type: \"Pooling\"\n  bottom: \"conv1\"\n  top: \"pool1\"\n  pooling_param {\n    pool: MAX\n    kernel_size: 2\n    stride: 2\n  }\n}\nlayer {\n  name: \"conv2\"\n  type: \"Convolution\"\n  bottom: \"pool1\"\n  top: \"conv2\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  convolution_param {\n    num_output: 50\n    kernel_size: 5\n    stride: 1\n    weight_filler {\n      type: \"xavier\"\n    }\n    bias_filler {\n      type: \"constant\"\n    }\n  }\n}\nlayer {\n  name: \"pool2\"\n  type: \"Pooling\"\n  bottom: \"conv2\"\n  top: \"pool2\"\n  pooling_param {\n    pool: MAX\n    kernel_size: 2\n    stride: 2\n  }\n}\nlayer {\n  name: \"fc1\"\n  type: \"InnerProduct\"\n  bottom: \"pool2\"\n  top: \"ip1\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 500\n    weight_filler {\n      type: \"xavier\"\n    }\n    bias_filler {\n      type: \"constant\"\n    }\n  }\n}\nlayer {\n  name: \"relu1\"\n  type: \"ReLU\"\n  bottom: \"ip1\"\n  top: \"ip1\"\n}\nlayer {\n  name: \"ip2\"\n  type: \"InnerProduct\"\n  bottom: \"ip1\"\n  top: \"ip2\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 7  #最后输出的分类数量\n    weight_filler {\n      type: \"xavier\"\n    }\n    bias_filler {\n      type: \"constant\"\n    }\n  }\n}\nlayer {\n  name: \"loss\"\n  type: \"Softmax\"\n  bottom: \"ip2\"\n  top: \"loss\"\n}\n\n```\n\n**deploy.prototxt**\n\n```\nname: \"LeNet\"\nlayer {\n  name: \"data\"\n  type: \"Input\"\n  top: \"data\"\n  input_param { shape: { dim: 1 dim: 3 dim: 20 dim: 20} }\n}\nlayer {\n  name: \"conv1\"\n  type: \"Convolution\"\n  bottom: \"data\"\n  top: \"conv1\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  convolution_param {\n    num_output: 20\n    kernel_size: 5\n    stride: 1\n    weight_filler {\n      type: \"xavier\"\n    }\n    bias_filler {\n      type: \"constant\"\n    }\n  }\n}\nlayer {\n  name: \"pool1\"\n  type: \"Pooling\"\n  bottom: \"conv1\"\n  top: \"pool1\"\n  pooling_param {\n    pool: MAX\n    kernel_size: 2\n    stride: 2\n  }\n}\nlayer {\n  name: \"conv2\"\n  type: \"Convolution\"\n  bottom: \"pool1\"\n  top: \"conv2\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  convolution_param {\n    num_output: 50\n    kernel_size: 5\n    stride: 1\n    weight_filler {\n      type: \"xavier\"\n    }\n    bias_filler {\n      type: \"constant\"\n    }\n  }\n}\nlayer {\n  name: \"pool2\"\n  type: \"Pooling\"\n  bottom: \"conv2\"\n  top: \"pool2\"\n  pooling_param {\n    pool: MAX\n    kernel_size: 2\n    stride: 2\n  }\n}\nlayer {\n  name: \"fc1\"\n  type: \"InnerProduct\"\n  bottom: \"pool2\"\n  top: \"ip1\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 500\n    weight_filler {\n      type: \"xavier\"\n    }\n    bias_filler {\n      type: \"constant\"\n    }\n  }\n}\nlayer {\n  name: \"relu1\"\n  type: \"ReLU\"\n  bottom: \"ip1\"\n  top: \"ip1\"\n}\nlayer {\n  name: \"ip2\"\n  type: \"InnerProduct\"\n  bottom: \"ip1\"\n  top: \"ip2\"\n  param {\n    lr_mult: 1\n  }\n  param {\n    lr_mult: 2\n  }\n  inner_product_param {\n    num_output: 7\n    weight_filler {\n      type: \"xavier\"\n    }\n    bias_filler {\n      type: \"constant\"\n    }\n  }\n}\nlayer {\n  name: \"loss\"\n  type: \"Softmax\"\n  bottom: \"ip2\"\n  top: \"loss\"\n}\n```\n\n\n\n### 训练脚本\n\n```shell\nEXAMPLE=/workspace/Caffe #工程的路径\nTOOLS=/opt/caffe/build/tools #caffe工具路径\nTRAIN_DATA_ROOT=$EXAMPLE/trainImages/ #训练集路径\nVAL_DATA_ROOT=$EXAMPLE/trainImages/ #测试集路径\nRESIZE=true #这里是resize图片，我这里时开启此功能，resize成20*20\nif $RESIZE; then\n  RESIZE_HEIGHT=20\n  RESIZE_WIDTH=20\nelse\n  RESIZE_HEIGHT=0\n  RESIZE_WIDTH=0\nfi\nif [ ! -d \"$TRAIN_DATA_ROOT\" ]; then\n  echo \"Error: 训练集路径错误: $TRAIN_DATA_ROOT\"\n  echo \"Set the TRAIN_DATA_ROOT variable in create_imagenet.sh to the path\" \\\n       \"where the ImageNet training data is stored.\"\n  exit 1\nfi\nif [ ! -d \"$VAL_DATA_ROOT\" ]; then\n  echo \"Error: 验证集路径错误: $VAL_DATA_ROOT\"\n  echo \"Set the VAL_DATA_ROOT variable in create_imagenet.sh to the path\" \\\n       \"where the ImageNet validation data is stored.\"\n  exit 1\nfi\n#生成前需要先删除已有的文件夹 必须，不然会报错\nrm -rf $EXAMPLE/train_lmdb\nrm -rf $EXAMPLE/val_lmdb\necho \"删除已有的lmdb文件夹\"\n#训练_lmdb\necho \"生成训练lmdb\"\nGLOG_logtostderr=1 $TOOLS/convert_imageset \\\n    --resize_height=$RESIZE_HEIGHT \\\n    --resize_width=$RESIZE_WIDTH \\\n    --shuffle \\\n    $TRAIN_DATA_ROOT \\\n    $EXAMPLE/train.txt \\\n    $EXAMPLE/train_lmdb\n#生成的训练lmdb文件所在文件夹，注意train_lmdb是文件夹名称\n#测试_lmdb\necho \"生成测试lmdb\"\nGLOG_logtostderr=1 $TOOLS/convert_imageset \\\n    --resize_height=$RESIZE_HEIGHT \\\n    --resize_width=$RESIZE_WIDTH \\\n    --shuffle \\\n    $VAL_DATA_ROOT \\\n    $EXAMPLE/val.txt \\\n    $EXAMPLE/val_lmdb\n#生成的测试lmdb文件所在文件夹，注意val_lmdb文件夹名称\n#解锁生成的文件夹\necho \"解锁lmdb文件夹\"\nchmod -R 777 $EXAMPLE/train_lmdb\nchmod -R 777 $EXAMPLE/val_lmdb\n\n#生成image_mean\n$TOOLS/compute_image_mean $EXAMPLE/train_lmdb \\\n        $EXAMPLE/train_mean.binaryproto\n$TOOLS/compute_image_mean $EXAMPLE/val_lmdb \\\n        $EXAMPLE/val_mean.binaryproto\n\n#Caffe训练\nmkdir -p $EXAMPLE/save_model\nchmod -R 777 $EXAMPLE/save_model\n\ncaffe train --solver=$EXAMPLE/model/solver.prototxt\nchmod -R 777 $EXAMPLE/save_model\necho \"完成\"\n```\n\n## 复制训练模型\n\n训练结束后，可以使用以下命令复制出训练结束的模型到宿主机，\n\n```bash\ndocker cp container_id:<docker容器内的路径> <本地保存文件的路径>\n```\n\n","tags":["Machine learning","Caffe","Docker","Dockerfile"],"categories":["Machine learning","Caffe"]},{"title":"RoboMaster视觉学习建议","url":"/2020/RoboMaster视觉学习建议/","content":"# 视觉学习建议\n## 目录\n* [程序语言](#程序语言)\n* [操作系统](#操作系统-Ubuntu)\n* [管理工具](#管理工具-Git)\n* [OpenCV](#OpenCV)\n* [数学基础](#数学基础)\n* [神经网络](#神经网络)\n* [推荐网站](#推荐网站)\n\n---\n\n## 程序语言\n### C++ \n​\tC++编写起来和C语言一样结构清晰，又在C语言的基础上增加了许多新的功能，还可以直接操作硬件，绝对是研发机器视觉最好的语言。\n\n​\t面向对象，封装、多态、继承这些思想绝对是编程的重点。小型项目可能感觉不出来，一旦项目代码超过千行，如何解耦和划分功能模块就成了所有人不得不面对的问题，而C++正好提供了面向对象的编程模型，又是静态编译型语言，速度快，是一定要学好的。\n\n​\t一个人写代码乱一点可能不要紧，但是多个人一起写代码就需要一个强有力的代码规范，比如变量的命名、类的命名、宏定义的命名和缩进格式等，这里我推荐大家看一下华为的[方舟编译器代码规范](https://www.openarkcompiler.cn/document/rules)，学习一下别人的代码是如何编写的。\n\n### Python\n\n​\tPython是我们用来编写深度学习的脚本语言，py的编写方式远比C++简单，开发小型项目的效率比C++高。但是Python是解释型语言，不进行编译，运行时底层有一个Pyhton解释器在动态解释代码，这就造成了Python在开发大型项目时运行速度会变慢，结构不清晰。\n\n​\t我们一般使用Python来训练机器学习模型，清洗机器学习所需要的数据集和部署大型神经网络。雷达站就是使用了YoloV4深度学习框架+DeepSort追踪器，YoloV4是C语言编写的框架，DeepSort是Python编写的，语言不同，但是使用py可以把这两个框架联合起来，共同为我们服务。这就是py的优点。\n\n\n\n---\n\n## 操作系统-Ubuntu\n​\t在车上跑的系统肯定不能是Windows，系统太过臃肿，有很多的功能我们并不需要，这时候Ubuntu就出场了，Ubuntu是一个基于Linux的、开源的操作系统。体统非常简洁，但是可以办到的事情却一点也不简单，视觉组的代码都是即可以运行在Windows上又可以运行在Ubuntu上的。平时使用WIndows开发，到了比赛的时候就在Ubuntu上跑代码。\n\n[windows环境下ubuntu usb系统盘制作教程](https://tutorials.ubuntu.com/tutorial/tutorial-create-a-usb-stick-on-windows#0)\n\n[安装Ubuntu系统](https://tutorials.ubuntu.com/tutorial/tutorial-install-ubuntu-desktop)\n\n一般有虚拟机安装，双系统，移动硬盘安装等方式安装ubuntu，这里不推荐虚拟机安装，因为过程占用内存过大，跑我们的代码会非常卡，这里我们推荐双系统，\tubuntu与windows共存，重启电脑即可切换系统，安装也相对简单。愿意买一块移动硬盘安装ubuntu也是不错的选择，不用占用原电脑硬盘容量，安装过程更加简单粗暴，甚至可以插入别人的电脑打自己的代码，随时随地都能开心地工作，是你在实验室赶进度的最佳选择。\n\n​\t安装完ubuntu后需要各位熟悉linux系统的一些基本命令行操作。比如ctrl+alt+t打开一个终端，cd进入某个目录，sudo获取root权限。rm删除某个文件或文件夹等等，初接触时会觉得繁琐，但熟练运用后你会觉得特别便捷高效。[参考链接](https://tutorials.ubuntu.com/tutorial/command-line-for-beginners#0)\n\n---\n\n## 管理工具-Git\n在战队待一整年，你需要和很多人合作，编写大量代码，代码改来改去容易乱套……\n\n所以你必须学会使用强大的版本管理工具——Git。\n\n在Git中，你可以看到队友们每次修改的内容，出现问题时，可以退回到任意一次修改之前。\n\nGit也具有强大的分支合并功能，视觉组平时开发时一个组员开发一个特定的分支，一个分支实现一个特定的功能，在功能开发和测试完毕后，就会合并到主分支。这样主分支的代码永远是可以使用的状态，新的功能的开发都在测试分支上。\n\n下图为方舟编译器代码的分支合并情况。可以看到优秀的代码工程都是多个模块并行开发，持续集成到主分支。\n\n![image-20200718165733341](https://img.peterli.club/img/image-20200718165733341.png)\n\n[官方网站（英文）](https://git-scm.com/)\n\n[推荐教程（中文）](https://rogerdudler.github.io/git-guide/index.zh.html)\n\n[教学游戏](https://learngitbranching.js.org/)\n\n---\n\n## OpenCV\n\n这是视觉组的任务重点，需要花最多的时间学习。\n\n[官方网站](https://opencv.org/)\n\nOpenCV是当前最具影响力的计算机视觉开源库。它的官网资料相当完整，在页面右边，有Online Documentation（在线文档）、Tutorials（教程）、User Q&A forum（问答论坛）都非常棒。\n\n在Tutorials里就有详细的安装教程，我们建议在你的Windows和Ubuntu上都安装OpenCV，这里要求各位安装opencv3及以上版本。\n\nOpenCV最推荐的资料还是官网文档。内容详细、更新速度快。大家也要尽快适应阅读英文资料，因为后面有些问题中文几乎查不到。\n\n不过这里仍然为想要快速熟悉opencv的朋友推荐一本opencv3的书，《OpenCV3编程入门》\n\n最好的学习方法其实就是多用，我们更推荐遇到问题的时候再去查找相关资料，完成视觉组面试前实战任务是最快速的opencv学习方法。\n\n---\n\n## 数学基础\n\n我们来谈谈简单有趣的数学基础，如果我直接和你说“线代很重要赶紧学”，可能你就体会不到我们这篇文章简单有趣的核心思想了，所以我打算举几个例子。\n\n好像有某位厉害的人说过：“矩阵就是映射。”\n\n比如说从世界坐标系映射到相机坐标系，从相机坐标系映射到像素坐标系。所以其实“从相机坐标系映射到像素坐标系”这句话翻译成人话就是相机内参，“从世界坐标系映射到相机坐标系”这句话翻译过来就是相机外参。就是说相机内参和外参其实都是用矩阵表示的，而且矩阵的应用不止这么一小点，比如特征的描述子，比如矩阵卷积来提取高维的特征等等，所以知道重要还不赶紧去学一波。\n\n顺便附上[祖传线代链接](https://m.bilibili.com/video/av6731067.html)\n\n而且也不仅仅是线代，概率论也是偶尔用得上的，比如让你描述一个轮廓的特征，你可能想到轮廓矩，这里的矩其实就是概率论里面的矩，把轮廓点集的坐标值当成一组随机变量来看这是很有意思的想法，有了这些概念你拿到api帮你算出来的矩心理也比较有底，知道怎么去用对吧。\n\n这么多底层的算法仔细想一想就头大，别担心，这当然不用你亲自去写了。OpenCV都已经帮你封装好了，RM视觉需要用到的矩阵运算方法一般OpenCV里都有，还有各种坐标点和相机参数的处理方法。\n\n---\n\n## 神经网络\n\n神经网络今年主要是用来识别车上的装甲板的，用了SVM训练装甲板模型进行检测。在雷达站上也用到了darknet深度学习框架，直接训练目标检测模型，外加TensorFlow做一些辅助处理。\n\n![image-20200718170342967](https://img.peterli.club/img/image-20200718170342967.png)\n\n---\n## 推荐网站\n### [stackoverflow](https://stackoverflow.com/)\n中文名：栈溢出。程序员交友网站，外国版的CSDN。\n\n可以解答你在计算机语言学习过程中的绝大多数疑惑。\n\n当然，提问和回答都是English的，不过程序员的专业英语比较简单，词汇量较少，看懂还是比较容易的。\n\n[如何优雅地使用 Stack Overflow？ - 猴子的回答 - 知乎](https://www.zhihu.com/question/20824615/answer/252350555)\n\n### [Github](https://github.com)\n没有使用过Github的程序员就不是一个真正的程序员，Github是世界上最大的开源库，别人家的优秀代码的集中地。\n\n[如何使用 GitHub？ - 杨晓辉的回答 - 知乎](https://www.zhihu.com/question/20070065/answer/117017972)\n\n### [Gitee](https://gitee.com)\n\n码云，中国的Github，没有Github访问和下载慢的烦恼，还有一系列本土化讨好中国程序员的功能，中国的开源项目一般都会发布在码云上一份。\n\n平时没事的时候就会逛[码云开源项目精选](https://gitee.com/explore)，Github上开源的都是英语，极少有中文，学习起来比较困难。在码云上热门的开源项目都会写完整的中文文档，帮助我们了解此项目。\n\n## One more thing\n\n\n为什么有的人代码写的这么烂，很多写死的代码，一点儿灵活性都没有，更没有规范，完全就是堆压。\n\n为什么有的人根本不知道怎么去抽象，并不清楚怎么样积累成公共组件，为什么他们改一个问题，通常会引出更多的问题？\n\n为什么他们的代码里的实现方案，让人看完之后恨的牙痒痒，想改又完全不能改，毕竟，正常工作的代码才是好代码？\n\n很大程度上是因为，很多程序员，不懂的代码的扩展性，不会面向未来编程。\n\n怎么叫做面向未来编程？\n\n**一个好的工程师，在听到需求的时候，可以根据自己的业务能力，判断出来这些需求中，哪些是有可能变化的，哪些是不太可能变化的。**\n\n**针对这些变化的内容，在编写的过程中，不会写死，而反复确认不可能会变化的需求，会写的简单一些，防止过度设计引起的复杂度。**\n\n简单说，当他拿到需求时，并不单纯是考虑这个需求怎么实现，还会考虑，自己设计的架构体系，扩展性在哪里，在他的眼里，看到的需求会被分解，折分，然后自己的技术方案，会挨个分解，分配。\n\n而且会拿着自己的架构体系跟领导沟通，讲清楚。\n\n在完成设计之后，他会很清楚的知道 ，自己设计的系统里，哪些变化是支持的，随便你改，我只需要改动一个很简单的内容。哪些是你绝对不能改的，你要改，我就必须花很大的代价，特别是在已经有线上数据的时候。\n\n\n\n哪一个参数应该直接写一个固定值？哪一个参数应该作为函数的入口参数？\n\n哪一个参数是需要在程序运行过程中动态调整的？哪一个参数是需要写进配置文件中的？\n\n\n\n什么样的变化是支持的？短信通道是有可能变化的，而调用短信通道的地方可能会有点多，所以我必须把短信通道抽象，并封装在一个公共接口，如果需要更换短信通道，我可能只需要更改一个配置文件就好了。\n\n那么什么样的变化是不支持的？我不需要不停机就更换短信通道的功能，除非你在后台系统中提前配置好，或者是有明确的需要，我做出这么一个东西出来。往往在前期，不会用到。\n\n\n\n一段代码（比如求两点距离），用到了两次以上，就要考虑写成一个函数调用。一个函数，在很多功能模块都要用到，就要考虑抽取成公共模块，供所有模块调用。\n\n","tags":["RoboMaster"],"categories":["RoboMaster"]},{"title":"Centos虚拟机多节点配置","url":"/2020/Centos虚拟机多节点配置/","content":"\n# VMware创建虚拟机\n\n## 单节点创建\n\n### 导入ISO镜像\n\n从[阿里源](https://mirrors.aliyun.com/centos/7/isos/x86_64/)下载Centos7镜像，并导入到VMware中，创建新的虚拟机。\n\n![image-20200708203719531](https://img.peterli.club/img/image-20200708203719531.png)\n\n### 给节点起名\n\n因为要创建多节点，所以给新的虚拟机命名为`Centos7_1`，之后创建更多的节点就按序号命名。\n\n![image-20200708203908179](https://img.peterli.club/img/image-20200708203908179.png)\n\n### 选择硬件配置\n\n虚拟机的硬件配置可以根据需要更改，如果不确定的话也可以安装完毕之后更改硬件配置。\n\n![image-20200708204132565](https://img.peterli.club/img/image-20200708204132565.png)\n\n### 安装Centos7\n\n选择完硬件配置之后的安装过程就和普通的Cenots安装过程一样，等待一段时间后就会进入Centos安装界面。\n\n**软件选择**这里选择开发及生成工作站，如果选择最小系统的话安装结束之后只有一个黑黑的命令行，看不到图形界面，不好操作。\n\n**安装位置**新手选择自动分区就可以了。\n\n![image-20200708205553927](https://img.peterli.club/img/image-20200708205553927.png)安装过程中可以顺便设置一下root密码。\n\n## 单节点网卡配置\n\n安装结束之后就可以看到令人兴奋的图形界面了，但是这个时候的Centos还不能联网，也不能和宿主机互通，使用`ifconfig`查看网卡信息也获取不到IP地址，所以需要一些设置。\n\n![image-20200708210953349](https://img.peterli.club/img/image-20200708210953349.png)\n\n### 配置VMware虚拟机网络设置\n\n接下来需要去虚拟机设置界面设置**网络适配器**为桥接模式，方便后续固定IP地址。\n\n![image-20200708211256177](https://img.peterli.club/img/image-20200708211256177.png)\n\n### 使用命令自动分配IP地址\n\n接下来需要切换到root用户(`su root`)，使用`dhclient`自动分配IP地址\n\n![image-20200708211828301](https://img.peterli.club/img/image-20200708211828301.png)\n\n分配完IP地址之后，我们再次查看IP地址就可以看到刚刚分配的IP地址了。\n\n### 固定IP地址\n\n刚才分配的IP地址其实是静态的，下次启动虚拟机就会变，所以我们需要进入网卡设置，固定IP地址`vi /etc/sysconfig/network-scripts/ifcfg-ens33`。这个文件初始化是这样的，我们需要更改其中的一些设置。按`Shift+I`插入，编辑文件。\n\n![image-20200708212414957](https://img.peterli.club/img/image-20200708212414957.png)\n\n配置好后的文件长成这个样，按`ESC`后`:wq`保存退出\n\n![image-20200708212933020](https://img.peterli.club/img/image-20200708212933020.png)\n\n退出后重启网卡`systemctl restart network.service`，重启成功后应该就可以访问外网了，ping百度试一下。\n\n![image-20200708213434191](https://img.peterli.club/img/image-20200708213434191.png)\n\n虚拟机访问外网已经成功了，这时候我们ping宿主机试一下（注意：**宿主机一定要关闭防火墙** ）。\n\n* 查看宿主机的IP地址：\n\n![image-20200708213949361](https://img.peterli.club/img/image-20200708213949361.png)\n\n* ping宿主机：\n\n![image-20200708214046652](https://img.peterli.club/img/image-20200708214046652.png)\n\n* 宿主机ping虚拟机\n\n  ![image-20200708214240873](https://img.peterli.club/img/image-20200708214240873.png)\n\n都可以ping通之后单一节点的虚拟机就已经配置好了。\n\n# 多节点虚拟机克隆\n\n## 克隆第二个节点\n\n单节点配置完成之后**关闭这个节点**，然后对这个节点进行克隆，克隆选项要选择完整克隆，就是这个节点的数据全部复制一份。\n\n![image-20200708214510890](https://img.peterli.club/img/image-20200708214510890.png)\n\n![image-20200708214652761](https://img.peterli.club/img/image-20200708214652761.png)\n\n## 更改第二个节点的IP地址\n\n进入第二个节点界面之后，再次使用`vi /etc/sysconfig/network-scripts/ifcfg-ens33`编辑节点的IP地址。（**一定要把第一个节点关机。不然会产生IP冲突！**）\n\n![image-20200708215252715](https://img.peterli.club/img/image-20200708215252715.png)\n\n编辑完成后使用`systemctl restart network.service`重启网卡，然后重复单一节点的ping验证操作。即**虚拟机ping外网**、**虚拟机ping宿主机**、**宿主机ping虚拟机**。\n\n都ping通了之后，第二个虚拟机节点就创建完成了，第三个和更多的节点都是按照这个流程进行创建。","tags":["Linux"],"categories":["Linux"]},{"title":"Git仓库代码提交统计","url":"/2020/Git仓库代码提交统计/","content":"\n## Git 代码统计\n\n### 查看仓库提交者排名前3\n\n```bash\ngit log --pretty='%aN' | sort | uniq -c | sort -k1 -n -r | head -n 3\n```\n\n![image-20200707143833213](https://img.peterli.club/img/image-20200707143833213.png)\n\n### 给Git查看某一个用户代码量\n\n```bash\ngit log --author=\"用户名\" --pretty=tformat: --numstat | awk '{ add += $1; subs += $2; loc += $1 - $2 } END { printf \"added lines: %s, removed lines: %s, total lines: %s\\n\", add, subs, loc }' \n```\n\n![image-20200707143344921](https://img.peterli.club/img/image-20200707143344921.png)\n\n### 统计每个人增删行数\n\n```bash\ngit log --format='%aN' | sort -u | while read name; do echo -en \"$name\\t\"; git log --author=\"$name\" --pretty=tformat: --numstat | awk '{ add += $1; subs += $2; loc += $1 - $2 } END { printf \"added lines: %s, removed lines: %s, total lines: %s\\n\", add, subs, loc }' -; done\n```\n\n![image-20200707143631623](https://img.peterli.club/img/image-20200707143631623.png)","tags":["工具人","Git"],"categories":["工具人","Git"]},{"title":"Nginx配置请求转发到后端","url":"/2020/Nginx配置请求转发到后端/","content":"### 新建一个nginx server\n\n在nginx的配置文件中新建一个server监听前端部署的端口\n\n```conf\nserver\n{\n\t#监听端口\n    listen 80;\n    server_name 网站名称;\n}\n```\n\n\n\n### 使用Nginx代理前端页面\n\n然后在server中添加一个`location`，就是把访问路径指向前端项目打包后的地址\n\n```conf\n    location / {\n    \troot 前端项目打包后的地址;\n    \tindex index.html index.htm;\n    }\n```\n\n### nginx请求转发到后端\n\n在部署前后端分离项目时，通常都要使用nginx把前端的请求转发到后端的接口上去，这就要配置nginx的`proxy_pass`功能。\n\n```conf\n\t# 转发请求到后端\n\tlocation /api/ {\n\t\tproxy_set_header Host $http_host;\n\t\tproxy_set_header X-Real-IP $remote_addr;\n\t\tproxy_set_header REMOTE-HOST $remote_addr;\n\t\tproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\t\t# proxy_redirect off;\n\t\t# proxy_set_header X-NginX-Proxy true;\n\t\tproxy_pass 后端接口地址;\n\t}\n```\n\n### server其他的配置\n\n```conf\n    #一键申请SSL证书验证目录相关设置\n    location ~ \\.well-known{\n        allow all;\n    }\n    #代理网站图标，可以注释\n    location  = /favicon.ico {\n      root /**/assets/;\n    }\n    \n    #禁止访问的文件或目录\n    location ~ ^/(\\.user.ini|\\.htaccess|\\.git|\\.svn|\\.project|LICENSE|README.md)\n    {\n        return 404;\n    }\n    \n    #访问日志\n    access_log  /**/日志名;\n    #错误日志\n    error_log  /**/日志名;\n```\n\n\n\n### 重载Nginx配置\n\n`nginx -s reload`\n\n### 查看Nginx访问日志\n\n`tail -f /**/日志名` \n\n","tags":["服务部署","Nginx"],"categories":["服务部署"]},{"title":"Java开源项目推荐","url":"/2020/Java开源项目推荐/","content":"\n## Spring Boot\n\n### [RuoYi](https://gitee.com/y_project/RuoYi)\n\n网站管理后台，网站会员中心，CMS，CRM，OA。所有前端后台代码封装过后十分精简易上手，出错概率低。同时支持移动客户端访问。\n\n功能：\n\n用户管理、部门管理、岗位管理、菜单管理、角色管理、字典管理、参数管理、通知公告、操作日志、登录日志、在线用户、定时任务、代码生成、系统接口、服务监控、在线构建器、连接池监视。\n\n### [renren-fast](https://gitee.com/renrenio/renren-fast)\n\n轻量级的，前后端分离的Java快速开发平台，能快速开发项目并交付\n\n### [coral](https://gitee.com/gemteam/coral)\n\nCoral 企业快速开发框架，基于SpringBoot2.2x，MyBatis，Shiro等主流框架开发；前端页面采用LayUi开发。本系统技术栈选型专门面向后台开发人员快速上手而选，适合所有中小型企业或开发团队，开箱即用。\n\n精细化权限管理，自定义菜单配置，安全身份认证，系统监控，代码生成，示例演示等。官方提供完善的API文档、部署文档、架构介绍文档以及视频教程帮助您快速学习入门，快速上手使用。\n\n## SpringCloud\n\n### [Cloud-platform](https://gitee.com/geek_qi/cloud-platform)\n\nCloud-Platform是国内首个基于`Spring \nCloud`微`服务`化`开发平台`，具有统一授权、认证后台管理系统，其中包含具备用户管理、资源权限管理、网关API\n管理等多个模块，支持多业务系统并行开发，可以作为后端服务的开发脚手架。代码简洁，架构清晰，适合学习和直接项目中使用。\n核心技术采用`Spring Boot \n2.1.2`以及`Spring Cloud (Greenwich.RELEASE)\n`相关核心组件，采用`Nacos`注册和配置中心，集成流量卫兵`Sentinel`，前端采用`vue-element-admin`组件，`Elastic Search`自行集成。\n\n### [RuoYi-Cloud](https://gitee.com/y_project/RuoYi-Cloud)\n\nRuoYi的SpringCloud版本\n\n## 商城\n\n### [mall4j](https://gitee.com/gz-yami/mall4j)\n\n一个基于spring boot、spring oauth2.0、mybatis、redis的轻量级、前后端分离、防范xss攻击、拥有分布式锁，为生产环境多实例完全准备，数据库为b2b2c设计，拥有完整sku和下单流程的完全开源商城\n\n### [微同商城](https://gitee.com/fuyang_lipengjun/platform)\n\n减少重复造轮子，开源微信小程序商城，秒杀、优惠券、多商户、直播卖货、三级分销等功能。\n\n## 秒杀\n\n### [SpringBoot-seckill](https://gitee.com/52itstyle/spring-boot-seckill)\n\n分布式秒杀系统，涉及到高并发环境下的数据一致性问题，消息队列，负载均衡，分布式锁，高并发的业务隔离性。\n\n## 支付\n\n### [roncoo-pay](https://gitee.com/roncoocom/roncoo-pay)\n\n龙果支付系统（roncoo-pay）是国内首款开源的互联网支付系统，拥有独立的账户体系、用户体系、支付接入体系、支付交易体系、对账清结算体系。目标是打造一款集成主流支付方式且轻量易用的支付收款系统，满足互联网业务系统打通支付通道实现支付收款和业务资金管理等功能。\n\n涉及到具体的支付业务流程，感受真实情况下的企业级业务逻辑。","tags":["Java","开源项目"],"categories":["Java","开源项目"]},{"title":"MySQL学习笔记","url":"/2020/MySQL学习笔记/","content":"\n\n## 数据库的好处\n\t1.持久化数据到本地\n\t2.可以实现结构化查询，方便管理\n\n\n\n## 数据库相关概念\n\t1、DB：数据库，保存一组有组织的数据的容器\n\t2、DBMS：数据库管理系统，又称为数据库软件（产品），用于管理DB中的数据\n\t3、SQL:结构化查询语言，用于和DBMS通信的语言\n\n## 数据库存储数据的特点\n\t1、将数据放到表中，表再放到库中\n\t2、一个数据库中可以有多个表，每个表都有一个的名字，用来标识自己。表名具有唯一性。\n\t3、表具有一些特性，这些特性定义了数据在表中如何存储，类似java中 “类”的设计。\n\t4、表由列组成，我们也称为字段。所有表都是由一个或多个列组成的，每一列类似java 中的”属性”\n\t5、表中的数据是按行存储的，每一行类似于java中的“对象”。\n\n\n\n## MySQL产品的介绍和安装\n\n### MySQL服务的启动和停止\n\t方式一：计算机——右击管理——服务\n\t方式二：通过管理员身份运行\n\tnet start 服务名（启动服务）\n\tnet stop 服务名（停止服务）\n\n\n### MySQL服务的登录和退出   \n\t方式一：通过mysql自带的客户端\n\t只限于root用户\n\t\n\t方式二：通过windows自带的客户端\n\t登录：\n\tmysql 【-h主机名 -P端口号 】-u用户名 -p密码\n\t\n\t退出：\n\texit或ctrl+C\n### MySQL的常见命令 \n\n\t1.查看当前所有的数据库\n\tshow databases;\n\t2.打开指定的库\n\tuse 库名\n\t3.查看当前库的所有表\n\tshow tables;\n\t4.查看其它库的所有表\n\tshow tables from 库名;\n\t5.创建表\n\tcreate table 表名(\n\t\n\t\t列名 列类型,\n\t\t列名 列类型，\n\t\t。。。\n\t);\n\t6.查看表结构\n\tdesc 表名;\n\n\n\t7.查看服务器的版本\n\t方式一：登录到mysql服务端\n\tselect version();\n\t方式二：没有登录到mysql服务端\n\tmysql --version\n\t或\n\tmysql --V\n\n\n\n### MySQL的语法规范\n\t1.不区分大小写,但建议关键字大写，表名、列名小写\n\t2.每条命令最好用分号结尾\n\t3.每条命令根据需要，可以进行缩进 或换行\n\t4.注释\n\t\t单行注释：#注释文字\n\t\t单行注释：-- 注释文字\n\t\t多行注释：/* 注释文字  */\n\n\n​\t\n​\t\n\n\n### SQL的语言分类\n\tDQL（Data Query Language）：数据查询语言\n\t\tselect \n\tDML(Data Manipulate Language):数据操作语言\n\t\tinsert 、update、delete\n\tDDL（Data Define Languge）：数据定义语言\n\t\tcreate、drop、alter\n\tTCL（Transaction Control Language）：事务控制语言\n\t\tcommit、rollback\n\n\n\n\n### SQL的常见命令\n\n\tshow databases； 查看所有的数据库\n\tuse 库名； 打开指定 的库\n\tshow tables ; 显示库中的所有表\n\tshow tables from 库名;显示指定库中的所有表\n\tcreate table 表名(\n\t\t字段名 字段类型,\t\n\t\t字段名 字段类型\n\t); 创建表\n\t\n\tdesc 表名; 查看指定表的结构\n\tselect * from 表名;显示表中的所有数据\n\n\n\n## DQL语言的学习\n### 进阶1：基础查询\n\t语法：\n\tSELECT 要查询的东西\n\t【FROM 表名】;\n\t\n\t类似于Java中 :System.out.println(要打印的东西);\n\t特点：\n\t①通过select查询完的结果 ，是一个虚拟的表格，不是真实存在\n\t② 要查询的东西 可以是常量值、可以是表达式、可以是字段、可以是函数\n\n### 进阶2：条件查询\n\t条件查询：根据条件过滤原始表的数据，查询到想要的数据\n\t语法：\n\tselect \n\t\t要查询的字段|表达式|常量值|函数\n\tfrom \n\t\t表\n\twhere \n\t\t条件 ;\n\t\n\t分类：\n\t一、条件表达式\n\t\t示例：salary>10000\n\t\t条件运算符：\n\t\t> < >= <= = != <>\n\t\n\t二、逻辑表达式\n\t示例：salary>10000 && salary<20000\n\t\n\t逻辑运算符：\n\t\n\t\tand（&&）:两个条件如果同时成立，结果为true，否则为false\n\t\tor(||)：两个条件只要有一个成立，结果为true，否则为false\n\t\tnot(!)：如果条件成立，则not后为false，否则为true\n\t\n\t三、模糊查询\n\t示例：last_name like 'a%'\n\n### 进阶3：排序查询\t\n\n\t语法：\n\tselect\n\t\t要查询的东西\n\tfrom\n\t\t表\n\twhere \n\t\t条件\n\t\n\torder by 排序的字段|表达式|函数|别名 【asc|desc】\n\n\n\n### 进阶4：常见函数\n#### 一、单行函数\n\t1、字符函数\n\t\tconcat拼接\n\t\tsubstr截取子串\n\t\tupper转换成大写\n\t\tlower转换成小写\n\t\ttrim去前后指定的空格和字符\n\t\tltrim去左边空格\n\t\trtrim去右边空格\n\t\treplace替换\n\t\tlpad左填充\n\t\trpad右填充\n\t\tinstr返回子串第一次出现的索引\n\t\tlength 获取字节个数\n\t\t\n\t2、数学函数\n\t\tround 四舍五入\n\t\trand 随机数\n\t\tfloor向下取整\n\t\tceil向上取整\n\t\tmod取余\n\t\ttruncate截断\n\t3、日期函数\n\t\tnow当前系统日期+时间\n\t\tcurdate当前系统日期\n\t\tcurtime当前系统时间\n\t\tstr_to_date 将字符转换成日期\n\t\tdate_format将日期转换成字符\n\t4、流程控制函数\n\t\tif 处理双分支\n\t\tcase语句 处理多分支\n\t\t\t情况1：处理等值判断\n\t\t\t情况2：处理条件判断\n\t\t\n\t5、其他函数\n\t\tversion版本\n\t\tdatabase当前库\n\t\tuser当前连接用户\n#### 二、分组函数\n\n\n\t\tsum 求和\n\t\tmax 最大值\n\t\tmin 最小值\n\t\tavg 平均值\n\t\tcount 计数\n\t\n\t\t特点：\n\t\t1、以上五个分组函数都忽略null值，除了count(*)\n\t\t2、sum和avg一般用于处理数值型\n\t\t\tmax、min、count可以处理任何数据类型\n\t    3、都可以搭配distinct使用，用于统计去重后的结果\n\t\t4、count的参数可以支持：\n\t\t\t字段、*、常量值，一般放1\n\t\n\t\t   建议使用 count(*)\n\n\n## 进阶5：分组查询\n\t语法：\n\tselect 查询的字段，分组函数\n\tfrom 表\n\tgroup by 分组的字段\n\n\n​\t\n​\t特点：\n​\t1、可以按单个字段分组\n​\t2、和分组函数一同查询的字段最好是分组后的字段\n​\t3、分组筛选\n​\t\t\t针对的表\t位置\t\t\t关键字\n​\t分组前筛选：\t原始表\t\tgroup by的前面\t\twhere\n​\t分组后筛选：\t分组后的结果集\tgroup by的后面\t\thaving\n​\t\n​\t4、可以按多个字段分组，字段之间用逗号隔开\n​\t5、可以支持排序\n​\t6、having后可以支持别名\n\n## 进阶6：多表连接查询\n\n\t笛卡尔乘积：如果连接条件省略或无效则会出现\n\t解决办法：添加上连接条件\n\n### 一、传统模式下的连接 ：等值连接——非等值连接\n\n\n\t1.等值连接的结果 = 多个表的交集\n\t2.n表连接，至少需要n-1个连接条件\n\t3.多个表不分主次，没有顺序要求\n\t4.一般为表起别名，提高阅读性和性能\n\n### 二、sql99语法：通过join关键字实现连接\n\n\t含义：1999年推出的sql语法\n\t支持：\n\t等值连接、非等值连接 （内连接）\n\t外连接\n\t交叉连接\n\t\n\t语法：\n\t\n\tselect 字段，...\n\tfrom 表1\n\t【inner|left outer|right outer|cross】join 表2 on  连接条件\n\t【inner|left outer|right outer|cross】join 表3 on  连接条件\n\t【where 筛选条件】\n\t【group by 分组字段】\n\t【having 分组后的筛选条件】\n\t【order by 排序的字段或表达式】\n\t\n\t好处：语句上，连接条件和筛选条件实现了分离，简洁明了！\n\n### 三、自连接\n\n案例：查询员工名和直接上级的名称\n\nsql99\n\n\tSELECT e.last_name,m.last_name\n\tFROM employees e\n\tJOIN employees m ON e.`manager_id`=m.`employee_id`;\n\nsql92\n\n\n\tSELECT e.last_name,m.last_name\n\tFROM employees e,employees m \n\tWHERE e.`manager_id`=m.`employee_id`;\n\n\n## 进阶7：子查询\n\n含义：\n\n\t一条查询语句中又嵌套了另一条完整的select语句，其中被嵌套的select语句，称为子查询或内查询\n\t在外面的查询语句，称为主查询或外查询\n\n特点：\n\n\t1、子查询都放在小括号内\n\t2、子查询可以放在from后面、select后面、where后面、having后面，但一般放在条件的右侧\n\t3、子查询优先于主查询执行，主查询使用了子查询的执行结果\n\t4、子查询根据查询结果的行数不同分为以下两类：\n\t① 单行子查询\n\t\t结果集只有一行\n\t\t一般搭配单行操作符使用：> < = <> >= <= \n\t\t非法使用子查询的情况：\n\t\ta、子查询的结果为一组值\n\t\tb、子查询的结果为空\n\t\t\n\t② 多行子查询\n\t\t结果集有多行\n\t\t一般搭配多行操作符使用：any、all、in、not in\n\t\tin： 属于子查询结果中的任意一个就行\n\t\tany和all往往可以用其他查询代替\n\n## 进阶8：分页查询\n\n应用场景：\n\n\t实际的web项目中需要根据用户的需求提交对应的分页查询的sql语句\n\n语法：\n\n\tselect 字段|表达式,...\n\tfrom 表\n\t【where 条件】\n\t【group by 分组字段】\n\t【having 条件】\n\t【order by 排序的字段】\n\tlimit 【起始的条目索引，】条目数;\n\n特点：\n\n\t1.起始条目索引从0开始\n\t\n\t2.limit子句放在查询语句的最后\n\t\n\t3.公式：select * from  表 limit （page-1）*sizePerPage,sizePerPage\n\t假如:\n\t每页显示条目数sizePerPage\n\t要显示的页数 page\n\n## 进阶9：联合查询\n\n引入：\n\tunion 联合、合并\n\n语法：\n\n\tselect 字段|常量|表达式|函数 【from 表】 【where 条件】 union 【all】\n\tselect 字段|常量|表达式|函数 【from 表】 【where 条件】 union 【all】\n\tselect 字段|常量|表达式|函数 【from 表】 【where 条件】 union  【all】\n\t.....\n\tselect 字段|常量|表达式|函数 【from 表】 【where 条件】\n\n特点：\n\n\t1、多条查询语句的查询的列数必须是一致的\n\t2、多条查询语句的查询的列的类型几乎相同\n\t3、union代表去重，union all代表不去重\n\n\n## DML语言\n\n### 插入\n\n语法：\n\tinsert into 表名(字段名，...)\n\tvalues(值1，...);\n\n特点：\n\n\t1、字段类型和值类型一致或兼容，而且一一对应\n\t2、可以为空的字段，可以不用插入值，或用null填充\n\t3、不可以为空的字段，必须插入值\n\t4、字段个数和值的个数必须一致\n\t5、字段可以省略，但默认所有字段，并且顺序和表中的存储顺序一致\n\n### 修改\n\n修改单表语法：\n\n\tupdate 表名 set 字段=新值,字段=新值\n\t【where 条件】\n修改多表语法：\n\n\tupdate 表1 别名1,表2 别名2\n\tset 字段=新值，字段=新值\n\twhere 连接条件\n\tand 筛选条件\n\n\n### 删除\n\n方式1：delete语句 \n\n单表的删除： ★\n\tdelete from 表名 【where 筛选条件】\n\n多表的删除：\n\tdelete 别名1，别名2\n\tfrom 表1 别名1，表2 别名2\n\twhere 连接条件\n\tand 筛选条件;\n\n\n方式2：truncate语句\n\n\ttruncate table 表名\n\n\n两种方式的区别【面试题】\n\t\n\t#1.truncate不能加where条件，而delete可以加where条件\n\t\n\t#2.truncate的效率高一丢丢\n\t\n\t#3.truncate 删除带自增长的列的表后，如果再插入数据，数据从1开始\n\t#delete 删除带自增长列的表后，如果再插入数据，数据从上一次的断点处开始\n\t\n\t#4.truncate删除不能回滚，delete删除可以回滚\n\n\n## DDL语句\n### 库和表的管理\n库的管理：\n\n\t一、创建库\n\tcreate database 库名\n\t二、删除库\n\tdrop database 库名\n表的管理：\n\t1.创建表\n\t\n\tCREATE TABLE IF NOT EXISTS stuinfo(\n\t\tstuId INT,\n\t\tstuName VARCHAR(20),\n\t\tgender CHAR,\n\t\tbornDate DATETIME\t\n\t);\n\tDESC studentinfo;\n\t2.修改表 alter\n\t语法：ALTER TABLE 表名 ADD|MODIFY|DROP|CHANGE COLUMN 字段名 【字段类型】;\n\t\n\t    1.修改字段名\n\t    ALTER TABLE studentinfo CHANGE  COLUMN sex gender CHAR;\n\t\n\t    2.修改表名\n\t    ALTER TABLE stuinfo RENAME [TO]  studentinfo;\n\t    3.修改字段类型和列级约束\n\t    ALTER TABLE studentinfo MODIFY COLUMN borndate DATE ;\n\t\n\t    4.添加字段\n\t\n\t    ALTER TABLE studentinfo ADD COLUMN email VARCHAR(20) first;\n\t4.删除字段\n\tALTER TABLE studentinfo DROP COLUMN email;\n\t\n\t3.删除表\n\t\n\tDROP TABLE [IF EXISTS] studentinfo;\n\n\n### 常见类型\n\n\t整型：\n\t\t\n\t小数：\n\t\t浮点型\n\t\t定点型\n\t字符型：\n\t日期型：\n\tBlob类型：\n\n\n\n### 常见约束\n\n\tNOT NULL\n\tDEFAULT\n\tUNIQUE\n\tCHECK\n\tPRIMARY KEY\n\tFOREIGN KEY\n\n## 数据库事务\n### 含义\n\t通过一组逻辑操作单元（一组DML——sql语句），将数据从一种状态切换到另外一种状态\n\n### 特点\n\t（ACID）\n\t原子性：要么都执行，要么都回滚\n\t一致性：保证数据的状态操作前和操作后保持一致\n\t隔离性：多个事务同时操作相同数据库的同一个数据时，一个事务的执行不受另外一个事务的干扰\n\t持久性：一个事务一旦提交，则数据将持久化到本地，除非其他事务对其进行修改\n\n相关步骤：\n\n\t1、开启事务\n\t2、编写事务的一组逻辑操作单元（多条sql语句）\n\t3、提交事务或回滚事务\n\n### 事务的分类：\n\n隐式事务，没有明显的开启和结束事务的标志\n\n\t比如\n\tinsert、update、delete语句本身就是一个事务\n\n\n显式事务，具有明显的开启和结束事务的标志\n\n\t\t1、开启事务\n\t\t取消自动提交事务的功能\n\t\t\n\t\t2、编写事务的一组逻辑操作单元（多条sql语句）\n\t\tinsert\n\t\tupdate\n\t\tdelete\n\t\t\n\t\t3、提交事务或回滚事务\n### 使用到的关键字\n\n\tset autocommit=0;\n\tstart transaction;\n\tcommit;\n\trollback;\n\t\n\tsavepoint  断点\n\tcommit to 断点\n\trollback to 断点\n\n\n### 事务的隔离级别:\n\n事务并发问题如何发生？\n\n\t当多个事务同时操作同一个数据库的相同数据时\n事务的并发问题有哪些？\n\n\t脏读：一个事务读取到了另外一个事务未提交的数据\n\t不可重复读：同一个事务中，多次读取到的数据不一致\n\t幻读：一个事务读取数据时，另外一个事务进行更新，导致第一个事务读取到了没有更新的数据\n\n如何避免事务的并发问题？\n\n\t通过设置事务的隔离级别\n\t1、READ UNCOMMITTED\n\t2、READ COMMITTED 可以避免脏读\n\t3、REPEATABLE READ 可以避免脏读、不可重复读和一部分幻读\n\t4、SERIALIZABLE可以避免脏读、不可重复读和幻读\n\n设置隔离级别：\n\n\tset session|global  transaction isolation level 隔离级别名;\n查看隔离级别：\n\n\tselect @@tx_isolation;\n\n## 视图\n含义：理解成一张虚拟的表\n\n视图和表的区别：\n\t\n\t\t使用方式\t占用物理空间\n\t\n\t视图\t完全相同\t不占用，仅仅保存的是sql逻辑\n\t\n\t表\t完全相同\t占用\n\n视图的好处：\n\n\n\t1、sql语句提高重用性，效率高\n\t2、和表实现了分离，提高了安全性\n\n### 视图的创建\n\t语法：\n\tCREATE VIEW  视图名\n\tAS\n\t查询语句;\n### 视图的增删改查\n\t1、查看视图的数据 ★\n\t\n\tSELECT * FROM my_v4;\n\tSELECT * FROM my_v1 WHERE last_name='Partners';\n\t\n\t2、插入视图的数据\n\tINSERT INTO my_v4(last_name,department_id) VALUES('虚竹',90);\n\t\n\t3、修改视图的数据\n\t\n\tUPDATE my_v4 SET last_name ='梦姑' WHERE last_name='虚竹';\n\n\n\n\t4、删除视图的数据\n\tDELETE FROM my_v4;\n### 某些视图不能更新\n\t包含以下关键字的sql语句：分组函数、distinct、group  by、having、union或者union all\n\t常量视图\n\tSelect中包含子查询\n\tjoin\n\tfrom一个不能更新的视图\n\twhere子句的子查询引用了from子句中的表\n### 视图逻辑的更新\n\t方式一：\n\tCREATE OR REPLACE VIEW test_v7\n\tAS\n\tSELECT last_name FROM employees\n\tWHERE employee_id>100;\n\t\n\t方式二:\n\tALTER VIEW test_v7\n\tAS\n\tSELECT employee_id FROM employees;\n\t\n\tSELECT * FROM test_v7;\n### 视图的删除\n\tDROP VIEW test_v1,test_v2,test_v3;\n### 视图结构的查看\t\n\tDESC test_v7;\n\tSHOW CREATE VIEW test_v7;\n\n## 存储过程\n\n含义：一组经过预先编译的sql语句的集合\n好处：\n\n\t1、提高了sql语句的重用性，减少了开发程序员的压力\n\t2、提高了效率\n\t3、减少了传输次数\n\n分类：\n\n\t1、无返回无参\n\t2、仅仅带in类型，无返回有参\n\t3、仅仅带out类型，有返回无参\n\t4、既带in又带out，有返回有参\n\t5、带inout，有返回有参\n\t注意：in、out、inout都可以在一个存储过程中带多个\n###创建存储过程\n语法：\n\n\tcreate procedure 存储过程名(in|out|inout 参数名  参数类型,...)\n\tbegin\n\t\t存储过程体\n\t\n\tend\n\n类似于方法：\n\n\t修饰符 返回类型 方法名(参数类型 参数名,...){\n\t\n\t\t方法体;\n\t}\n\n注意\n\n\t1、需要设置新的结束标记\n\tdelimiter 新的结束标记\n\t示例：\n\tdelimiter $\n\t\n\tCREATE PROCEDURE 存储过程名(IN|OUT|INOUT 参数名  参数类型,...)\n\tBEGIN\n\t\tsql语句1;\n\t\tsql语句2;\n\t\n\tEND $\n\t\n\t2、存储过程体中可以有多条sql语句，如果仅仅一条sql语句，则可以省略begin end\n\t\n\t3、参数前面的符号的意思\n\tin:该参数只能作为输入 （该参数不能做返回值）\n\tout：该参数只能作为输出（该参数只能做返回值）\n\tinout：既能做输入又能做输出\n\n\n调用存储过程\n\tcall 存储过程名(实参列表)\n## 函数\n\n\n### 创建函数\n\n学过的函数：LENGTH、SUBSTR、CONCAT等\n语法：\n\n\tCREATE FUNCTION 函数名(参数名 参数类型,...) RETURNS 返回类型\n\tBEGIN\n\t\t函数体\n\t\n\tEND\n\n### 调用函数\n\tSELECT 函数名（实参列表）\n\n\n\n\n\n### 函数和存储过程的区别\n\n\t\t\t关键字\t\t调用语法\t返回值\t\t\t应用场景\n\t函数\t\tFUNCTION\tSELECT 函数()\t只能是一个\t\t一般用于查询结果为一个值并返回时，当有返回值而且仅仅一个\n\t存储过程\tPROCEDURE\tCALL 存储过程()\t可以有0个或多个\t\t一般用于更新\n\n\n## 流程控制结构\n\n### 系统变量\n一、全局变量\n\n作用域：针对于所有会话（连接）有效，但不能跨重启\n\n\t查看所有全局变量\n\tSHOW GLOBAL VARIABLES;\n\t查看满足条件的部分系统变量\n\tSHOW GLOBAL VARIABLES LIKE '%char%';\n\t查看指定的系统变量的值\n\tSELECT @@global.autocommit;\n\t为某个系统变量赋值\n\tSET @@global.autocommit=0;\n\tSET GLOBAL autocommit=0;\n\n二、会话变量\n\n作用域：针对于当前会话（连接）有效\n\n\t查看所有会话变量\n\tSHOW SESSION VARIABLES;\n\t查看满足条件的部分会话变量\n\tSHOW SESSION VARIABLES LIKE '%char%';\n\t查看指定的会话变量的值\n\tSELECT @@autocommit;\n\tSELECT @@session.tx_isolation;\n\t为某个会话变量赋值\n\tSET @@session.tx_isolation='read-uncommitted';\n\tSET SESSION tx_isolation='read-committed';\n\n### 自定义变量\n一、用户变量\n\n声明并初始化：\n\n\tSET @变量名=值;\n\tSET @变量名:=值;\n\tSELECT @变量名:=值;\n赋值：\n\n\t方式一：一般用于赋简单的值\n\tSET 变量名=值;\n\tSET 变量名:=值;\n\tSELECT 变量名:=值;\n\n\n\t方式二：一般用于赋表 中的字段值\n\tSELECT 字段名或表达式 INTO 变量\n\tFROM 表;\n\n使用：\n\n\tselect @变量名;\n\n二、局部变量\n\n声明：\n\n\tdeclare 变量名 类型 【default 值】;\n赋值：\n\n\t方式一：一般用于赋简单的值\n\tSET 变量名=值;\n\tSET 变量名:=值;\n\tSELECT 变量名:=值;\n\n\n\t方式二：一般用于赋表 中的字段值\n\tSELECT 字段名或表达式 INTO 变量\n\tFROM 表;\n\n使用：\n\n\tselect 变量名\n\n\n\n二者的区别：\n\n\t\t\t作用域\t\t\t定义位置\t\t语法\n用户变量\t当前会话\t\t会话的任何地方\t\t加@符号，不用指定类型\n局部变量\t定义它的BEGIN END中 \tBEGIN END的第一句话\t一般不用加@,需要指定类型\n\n### 分支\n一、if函数\n\t语法：if(条件，值1，值2)\n\t特点：可以用在任何位置\n\n二、case语句\n\n语法：\n\n\t情况一：类似于switch\n\tcase 表达式\n\twhen 值1 then 结果1或语句1(如果是语句，需要加分号) \n\twhen 值2 then 结果2或语句2(如果是语句，需要加分号)\n\t...\n\telse 结果n或语句n(如果是语句，需要加分号)\n\tend 【case】（如果是放在begin end中需要加上case，如果放在select后面不需要）\n\t\n\t情况二：类似于多重if\n\tcase \n\twhen 条件1 then 结果1或语句1(如果是语句，需要加分号) \n\twhen 条件2 then 结果2或语句2(如果是语句，需要加分号)\n\t...\n\telse 结果n或语句n(如果是语句，需要加分号)\n\tend 【case】（如果是放在begin end中需要加上case，如果放在select后面不需要）\n\n\n特点：\n\t可以用在任何位置\n\n三、if elseif语句\n\n语法：\n\n\tif 情况1 then 语句1;\n\telseif 情况2 then 语句2;\n\t...\n\telse 语句n;\n\tend if;\n\n特点：\n\t只能用在begin end中！！！！！！！！！！！！！！！\n\n\n三者比较：\n\t\t\t应用场合\n\tif函数\t\t简单双分支\n\tcase结构\t等值判断 的多分支\n\tif结构\t\t区间判断 的多分支\n\n\n### 循环\n\n语法：\n\n\n\t【标签：】WHILE 循环条件  DO\n\t\t循环体\n\tEND WHILE 【标签】;\n\n特点：\n\n\t只能放在BEGIN END里面\n\t\n\t如果要搭配leave跳转语句，需要使用标签，否则可以不用标签\n\t\n\tleave类似于java中的break语句，跳出所在循环！！！","tags":["数据库","MySQL"],"categories":["数据库","MySQL"]},{"title":"VS2019统计代码行数","url":"/2020/VS2019统计代码行数/","content":"\n程序员如何获得满足感？当然是代码写的越多越有满足感，看到自己写的几千行代码，不禁老泪纵横，获得感MAX。虽然编译器会显示当前打开文件的行数，但是不能统计整个项目所有代码的行数，那么如何获得整个项目的代码行数呢？\n\n在VS中使用快捷键打开查找与搜索`CTRL+SHIFT+F`\n在查找内容中输入`^b*[^:b#/]+.*$`\n查找范围选择当前项目\n在查找选项中选择使用正则表达式\n查找以下文件类型中输入`*.cpp;*.h`（以C++为例）\n结果选项中选择查找结果表\n点击查找全部即可获得结果\n![](https://i.loli.net/2019/12/02/apOMPNevGSDHFzs.png)\n结果：\n![](https://i.loli.net/2019/12/02/6dgQA8ewUFKnTmC.png)","tags":["工具人","VS"],"categories":["工具人","VS"]},{"title":"Tf2.X安装指南","url":"/2020/Tf2-X安装指南/","content":"## 下载Anaconda\n\n从清华源下载 Anaconda\n[下载地址](https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/)，选择自己系统的新版下载。\n下载完成后一路next 在这个位置需要添加环境变量，便于以后从cmd访问conda\n选Add Anaconda to my PATH environment variable\n安装结束后重启计算机\n\n## 配置Anaconda\n\nwin+R键，然后输入cmd并回车 在命令行输入\n\n### 更新conda源\n\n`conda config --set show_channel_urls yes`\n退出cmd，用记事本打开`C:\\Users\\@@@.condarc`***@@@为你的用户名（这个文件默认是隐藏的）***，使用以下内容替换.condarc的内容：\n```\n    channels:\n      - defaults\n    show_channel_urls: true\n    default_channels:\n      - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n      - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free\n      - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r\n    custom_channels:\n      conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n      msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n      bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n      menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n      pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n      simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n```\n保存退出，再次打开cmd\n\n`pip install pip -U`\n\n### 更换清华源\n\n`pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple`\n\n\n### 创建开发环境\n\n`conda create -n tf2.0 python=3.6`\n\n### 进入创建的开发环境\n\n`conda activate tf2.0`\n\n\n### 安装tensorflow GPU版本\n\n`pip install tensorflow-gpu`\n\n## 测试tensorflow-gpu版本是否安装成功\n\n`pip install ipython` `ipython` \n在In[1]:中输入`iimport tensorflow as tf`回车，没有报错即为成功 在\nIn[2]:中输入 `tf.__version__`   回车，显示2.*即为成功 在\nIn[3]:中输入`tf.test.is_gpu_available()`回车，输出TRUE即为成功\n\n## 安装PyCharm运行tensorflow\n\n百度自行下载PyCharm并破解\n\n### 配置PyCharm与TensorFlow\n\n打开pycahrm，进行新建项目的一些设置 出现如下界面\n选择运行环境。选中Existing Interpreter，点击右边设置按钮，选择Add Local\n![img](https://i.loli.net/2019/12/02/79vVbeGZPhIAirl.png)\n点击Conda Enviroment，选择环境\n![img2](https://i.loli.net/2019/12/02/r1KOpGyeDAgnuTJ.png)\n进入Anaconda安装路径，选择envs文件夹，里面有建立的环境，选择之前建立的tensorflow环境中的python.exe\n\n### test.py文件测试tensorflow\n\n这是一个简单利用MNIST数据集构建网络运行的小程序，程序会自动从网上下载MNIST数据集并进行训练\n```python\n    from __future__ import absolute_import, division, print_function, unicode_literals\n    import tensorflow as tf\n    mnist = tf.keras.datasets.mnist\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    x_train, x_test = x_train / 255.0, x_test / 255.0\n    model = tf.keras.models.Sequential([\n      tf.keras.layers.Flatten(input_shape=(28, 28)),\n      tf.keras.layers.Dense(128, activation='relu'),\n      tf.keras.layers.Dropout(0.2),\n      tf.keras.layers.Dense(10, activation='softmax')\n    ])\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    model.fit(x_train, y_train, epochs=5)\n    model.evaluate(x_test,  y_test, verbose=2)\n```","tags":["Machine learning","TensorFlow2"],"categories":["Machine learning","TensorFlow2"]},{"title":"GIt删除大文件","url":"/2020/GIt删除大文件/","content":"# GIt从历史记录中删除大文件和查看文件大小\n\n## 查看代码库的文件大小列表\n\n```sh\ngit rev-list --objects --all \\\n| git cat-file --batch-check='%(objecttype) %(objectname) %(objectsize) %(rest)' \\\n| sed -n 's/^blob //p' \\\n| sort --numeric-sort --key=2 \\\n| cut -c 1-12,41- \\\n| $(command -v gnumfmt || echo numfmt) --field=2 --to=iec-i --suffix=B --padding=7 --round=nearest\n```\n\n\n\n## 从所有分支和历史记录中删除大文件\n\n```sh\ngit filter-branch --force --index-filter 'git rm --cached -r --ignore-unmatch 文件的相对路径' --prune-empty --tag-name-filter cat -- --all\n\n```\n\n## 回收git存储空间\n\n```sh\nrm -rf .git/refs/original/ \ngit reflog expire --expire=now --all\ngit gc --prune=now\ngit gc --aggressive --prune=now\n```\n\n\n\n## 强制推送到远程仓库\n\n```shell\ngit push origin --force --all\n```","tags":["工具人","Git"],"categories":["工具人","Git"]},{"title":"YoloV4使用体验","url":"/2020/YoloV4使用体验/","content":"\n# YOLOV4首发使用体验\n\n## YOLOV4训练自己的数据集\n\n> 训练配置基本上就是官方文档的翻译，加上一些自己的理解，英语好的可以直接看[官方文档](https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects)\n\n### 更改网络配置参数（cfg文件）\n\n1. 从yolo给的cfg文件中复制`yolov4-custom.cfg`到自己的项目里，喜欢的可以改一个名字。\n\n2. 更改`batch=64` `subdivisions=64`，YOLOV4提高了训练的要求，我的笔记本的1060居然被嫌弃了，改成64也不能正常开始训练，只好借用高性能台式2070来训练了\n\n3. 设置 `max_batches`为(`classes*2000` 但是最小不能小于 `4000`), 意思就是你有三个目标需要检测就设置 `max_batches=6000`\n\n4. 设置`steps `为80%和90%的 `max_batches`，意思就是你有三个目标需要检测就设置 `steps=4800,5400`\n\n5. 设置网络的大小为 `width=416 height=416` 或任意一个32的倍数，yolov4默认是608*608，这就挺好的，没有必要改这个，改了这个之后后边的`anchors`锚点也需要改一下，如果你不知道怎么改锚点，就不用更改网络大小了。YOLO在检测的时候会自动resize你输入的图片为设置的大小。\n\n6. 下图就是一个实例：\n\n   ![image-20200426224150938](https://object-lealaxy.oss-cn-beijing.aliyuncs.com/img/image-20200426224150938.png)\n\n7. 下一步就是更改具体的yolo层的配置了，yolov4和v3一样，还是有三个yolo层，这三个yolo层都需要根据自己的数据集改一下，如果你在cfg里找不到可以搜索一下。\n\n8. 更改classes为你自己的标签数量，然后更改yolo层上边的convolutional层的`filters`的数量为filters=(classes + 5)x3 。也就是说如果你有5个classes，就需要设置filters为（5+5）*3=30，就像下图展示的那样。这一步很关键，**三个YOLO层都需要这样设置，不能只设置一个YOLO层**。\n\n      ![image-20200426224515277](https://object-lealaxy.oss-cn-beijing.aliyuncs.com/img/image-20200426224515277.png)\n\n9. 如果你用`[Gaussian_yolo]`的话是需要特殊的设置的，这里就不讲了，用到的话可以自己去看官方文档。\n\n### 转化标注和制作train.txt\n\n这一步比较简单，在我的另一篇博客里也写过了，就不赘述了。\n\n### 编译Darknet\n\n这一步网络上有很多的教程了，我就不再重复写一遍，直接贴一篇我觉的写的很好的\n\n> [编译darknet](https://blog.csdn.net/qq_38737790/article/details/92797119)\n>\n> [CUDA和cuDNN安装及配置环境变量](https://blog.csdn.net/qq_37296487/article/details/83028394?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3&utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3)\n\n需要注意的是，编译darknet需要安装cuda和cuDNN并配置环境变量，不一定要安装CUDA9.0版本的，其他版本也可以\n\n### 开始训练\n\n如果你的环境和配置文件都准备好了，就可以开始训练了，不过这一步需要下载预训练权重，官方文档是从墙外下载的，我也好心上传了一份“[yolov4.conv.137](http://img.peterli.club/objectyolov4.conv.137)”，点击就可以直接下载。\n\t\ndarknet的训练代码也非常简单`darknet detector train custom.data yolov4-custom.cfg yolov4.conv.137`，直接打开cmd运行这句话就可以了，然后就可以开始训练了。\n\n## 训练YOLOV4之后的体验\n\n先贴出来我训练的mAP，可以看到YOLOV4训练的结果比较惨淡，在同样的数据集的情况下甚至还不如YOLOV3，可能是我使用的有点问题，不知道为什么会出现这样的情况。这个模型训练到后期loss一直在7.X降不下来，而同数据集下的YOLOV3就可以把loss降到2.X。\n\t\n下图是YOLOV4训练过后的map，然后是相同数据集训练相同次数的yolov3的训练map。YOLOV4和YOLOV3我都是使用了官方推荐的训练配置进行训练，可以看到YOLOV3的效果要比4好一点，而且检测时间也比较快。\n\n测试命令：`darknet.exe detector map data/custom.data yolov4-custom.cfg backup\\yolov4-custom_last.weights`\n\n![image-20200427122101454](https://img.peterli.club/img/image-20200427122101454.png)\n\n![image-20200427122221534](https://img.peterli.club/img/image-20200427122221534.png)\n\n训练完成之后，我又详细阅读了官方文档，上边说最终的loss可以降到从`0.05`（对于小模型和简单数据集）到`3.0`（对于大模型和困难数据集）。YOLOV3确实是达到了这个要求的，但是YOLOV4最终loss是稳定在7.X的，也许是我使用v4的方法有些不对，并没有看到很高的提升。","tags":["Machine learning","YOLOV4"],"categories":["Machine learning","YOLOV4"]},{"title":"基于自定义数据集的Caffe模型生成","url":"/2020/基于自定义数据集的Caffe模型生成/","content":"\n![](https://www.microsoft.com/en-us/CMSImages/AI_AIPlatform_Caffe2_491x276.jpg?version=23c76694-e7db-6da1-65cf-8248206ea83e)\n首先，整个的工程目录大概是这样的:每个文件对应的功能会在后面的文章中介绍，现在可以先不急于创建整个工程目录。\n![image.png](https://i.loli.net/2019/12/14/pojktLWQgvVHTJM.png)\n\n准备数据集\n----------\n\n### 给数据集重新命名\n\n每一张图片前都插入图片的标签，可以使用ubuntu的批量重命名的功能．比如说我要做一个二分类的网络，命名格式应该是这样的：![2019-12-14\n22-09-08屏幕截图.png](https://i.loli.net/2019/12/14/s2Bcw7SQqrOlVIY.png)其中每个图片的开头都是图片的标签，这样方便与生成图片txt\n\n### 新建两个文件夹用于存放数据集和验证集\n\n![](https://img-blog.csdn.net/20170822235642873?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvSGVsbG9IYWlibw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)\n训练集和测试集的图片比例为８：２，也就是说你一共有一百张图片，８０张放入train文件夹里．２０张放入val文件夹里\n\n### 生成train.txt和val.txt用来保存图片名称和对应标签\n\n新建一个python文件，命名为`get_data.py`\n\n    # -*- coding: UTF-8 -*-\n    import os\n    import re\n    path_train = #\"train文件夹的路径\" #建议是用绝对路径\n    path_val = #\"val文件夹的路径\"\n    path_txt = #\"生成txt文件夹的路径\"\n    if not os.path.exists(path_train):\n        print (\"训练文件夹路径不存在！\")\n        ox._exit()\n    else:\n        print (\"成功加载训练文件夹\")\n    if not os.path.exists(path_val):\n        print (\"验证文件夹路径不存在！\")\n        ox._exit()\n    else:\n        print (\"成功加载验证文件夹\")\n    file_train = open(path_txt + '/train.txt','wt')\n    file_val = open(path_txt + '/val.txt','wt')\n    file_train.truncate()\n    file_val.truncate()\n    pa = r\".+(?=\\.)\"\n    pattern = re.compile(pa)\n    print (\"正在生成train.txt\")\n    for filename in os.listdir(path_train):\n        group_lable = pattern.search(filename)\n        str_label = str(group_lable.group())\n        if str_label[0]=='0':\n            train_lable = '0'\n        elif str_label[0]=='1':\n            train_lable = '1'\n        else:\n            print (\"文件命名格式错误！\")\n            ox._exit()\n        file_train.write(filename+' '+train_lable+'\\n')\n    print (\"成功生成train.txt\")\n    print (\"-----------------------------------\")\n    print (\"正在生成val.txt\")\n    for filename in os.listdir(path_val):\n        group_lable = pattern.search(filename)\n        str_label = str(group_lable.group())\n        if str_label[0]=='0':\n            val_lable = '0'\n        elif str_label[0]=='1':\n            val_lable = '1'\n        else:\n            print (\"文件命名格式错误！\")\n            ox._exit()\n        file_val.write(filename+' '+val_lable+'\\n')\n    print (\"成功生成val.txt\")\n    print (\"退出程序\")\n\n然后运行脚本`sudo python get_data.py`\n这样就生成了两个txt文件，如果你的脚本不报错，文件应该是长成这个样的．![2019-12-1422-22-21屏幕截图.png](https://i.loli.net/2019/12/14/GjP5XkZ2vgNSQa7.png)\n\n准备LMDB文件和均值文件\n----------------------\n\n### ＬＭＤＢ文件\n\n我们要生成能让网络结构文件“读懂”的标签文件格式——lmdb，其实还有很多其它格式：leveldb、hdf5等等。那么我们是以哪种形式生成lmdb文件呢？用的是caffe提供的convert\\_imageset功能，让txt格式文件转换成lmdb格式\n我们通过以下脚本实现转换： ***需要改一下前两个路径***\n`create_imagenet.sh`\n\n    EXAMPLE=/home/peter/桌面/caffe自定义数据集 #工程的路径 \n    TOOLS=/home/peter/桌面/caffeBuild/tools #caffe工具路径,一般是在caffe目录下的tools文件夹下 \n    TRAIN_DATA_ROOT=$EXAMPLE/train/ #训练集路径 \n    VAL_DATA_ROOT=$EXAMPLE/val/ #测试集路径 \n    RESIZE=true #这里是resize图片，我这里时开启此功能，resize成20*20\n    if $RESIZE; then\n      RESIZE_HEIGHT=20\n      RESIZE_WIDTH=20\n    else\n      RESIZE_HEIGHT=0\n      RESIZE_WIDTH=0\n    fi\n    if [ ! -d \"$TRAIN_DATA_ROOT\" ]; then\n      echo \"Error: 训练集路径错误: $TRAIN_DATA_ROOT\"\n      echo \"Set the TRAIN_DATA_ROOT variable in create_imagenet.sh to the path\" \\\n           \"where the ImageNet training data is stored.\"\n      exit 1\n    fi\n    if [ ! -d \"$VAL_DATA_ROOT\" ]; then\n      echo \"Error: 验证集路径错误: $VAL_DATA_ROOT\"\n      echo \"Set the VAL_DATA_ROOT variable in create_imagenet.sh to the path\" \\\n           \"where the ImageNet validation data is stored.\"\n      exit 1\n    fi\n    #生成前需要先删除已有的文件夹 必须，不然会报错\n    rm -rf $EXAMPLE/train_lmdb\n    rm -rf $EXAMPLE/val_lmdb\n    echo \"删除已有的lmdb文件夹\"\n    #训练_lmdb\n    echo \"生成训练lmdb\"\n    GLOG_logtostderr=1 $TOOLS/convert_imageset \\\n        --resize_height=$RESIZE_HEIGHT \\\n        --resize_width=$RESIZE_WIDTH \\\n        --shuffle \\\n        $TRAIN_DATA_ROOT \\\n        $EXAMPLE/train.txt \\\n        $EXAMPLE/train_lmdb\n    #生成的训练lmdb文件所在文件夹，注意train_lmdb是文件夹名称\n    #测试_lmdb\n    echo \"生成测试lmdb\"\n    GLOG_logtostderr=1 $TOOLS/convert_imageset \\\n        --resize_height=$RESIZE_HEIGHT \\\n        --resize_width=$RESIZE_WIDTH \\\n        --shuffle \\\n        $VAL_DATA_ROOT \\\n        $EXAMPLE/val.txt \\\n        $EXAMPLE/val_lmdb\n    #生成的测试lmdb文件所在文件夹，注意val_lmdb文件夹名称\n    #解锁生成的文件夹\n    echo \"解锁lmdb文件夹\"\n    chmod -R 777 $EXAMPLE/train_lmdb\n    chmod -R 777 $EXAMPLE/val_lmdb\n    echo \"完成\"\n\n保存退出然后运行`sudo sh create_imagenet.sh`\n脚本正常运行完之后应该是这个样子的,如果有报错多半是你的路径填的不对,仔细检查一下.\n![2019-12-1422-30-13屏幕截图.png](https://i.loli.net/2019/12/14/o6sL5hOWl1DpN7i.png)\n\n### 均值文件\n\n生成均值文件的脚本比较简单，路径都可以从上一个脚本复制过来\n`compute_image_mean.sh`\n\n    EXAMPLE=/home/peter/桌面/caffe自定义数据集 #工程的路径 \n    TOOLS=/home/peter/桌面/caffeBuild/tools #caffe工具路径 \n    $TOOLS/compute_image_mean $EXAMPLE/train_lmdb \\\n            $EXAMPLE/train_mean.binaryproto\n    $TOOLS/compute_image_mean $EXAMPLE/val_lmdb \\\n            $EXAMPLE/val_mean.binaryproto\n    echo \"完成\"\n\n脚本运行完成后应该生成了一个这样的文件\n![image.png](https://i.loli.net/2019/12/14/K3a5eNRfSubonkD.png)\n\n准备网络结构文件和训练文件\n--------------------------\n\n这个文件，是网络的结构文件，一般说设计网络，狭义上就是指的设计这个文件的内容，对于初学者，我建议你们先用简单的模板训练，在看懂的基础上，了解这个文件的结构，以及自己如何去设计这个文件。\ncaffe自带的demo中有很简单的，也很经典的LeNet、AlexNet、GoogLeNet模型(google为了向经典的LeNet致敬，才将L大写)，再次强烈建议大家将这些模型的结构看一遍，弄懂为何这样设计，这对你以后自己去设计网络有很大的启发，当然基本的数理统计算法，比如经典的BP算法、autoencoder、基本的激活函数sigmoid函数LRN函数等等，这些需要根据格个人情况自行补课。\n这里给出了一个简单的网络结构文件．只需要更改一下路径和一些简单的信息即可使用\n在工程目录下新建一个make\\_model文件夹，在文件夹中新建一些文档\n![image.png](https://i.loli.net/2019/12/14/9NqC8RnvopmBEdg.png)\n![image.png](https://i.loli.net/2019/12/14/5hFyXB7GVnHsqjE.png)\n\n### **train\\_val.prototxt**\n\n这个文件需要改一些训练集的路径和最后输出的分类数量\n\n    name: \"LeNet\"\n    layer {\n      name: \"mnist\"\n      type: \"Data\"\n      top: \"data\"\n      top: \"label\"\n      include {\n        phase: TRAIN\n      }\n      transform_param {\n        mirror: true\n        crop_size: 20\n        mean_file: \"/home/peter/桌面/caffe自定义数据集/train_mean.binaryproto\" #均值文件的路径\n      }\n      data_param {\n        source: \"/home/peter/桌面/caffe自定义数据集/train_lmdb\" #训练LMDB的路径\n        batch_size: 32\n        backend: LMDB\n      }\n    }\n    layer {\n      name: \"mnist\"\n      type: \"Data\"\n      top: \"data\"\n      top: \"label\"\n      include {\n        phase: TEST \n      }\n      transform_param {\n        mirror: false\n        crop_size: 20\n        mean_file: \"/home/peter/桌面/caffe自定义数据集/val_mean.binaryproto\" #均值文件的路径\n      }\n      data_param {\n        source: \"/home/peter/桌面/caffe自定义数据集/val_lmdb\" #验证LMDB的路径\n        batch_size: 50\n        backend: LMDB\n      }\n    }\n    layer {\n      name: \"conv1\"\n      type: \"Convolution\"\n      bottom: \"data\"\n      top: \"conv1\"\n      param {\n        lr_mult: 1\n      }\n      param {\n        lr_mult: 2\n      }\n      convolution_param {\n        num_output: 20\n        kernel_size: 5\n        stride: 1\n        weight_filler {\n          type: \"xavier\"\n        }\n        bias_filler {\n          type: \"constant\"\n        }\n      }\n    }\n    layer {\n      name: \"pool1\"\n      type: \"Pooling\"\n      bottom: \"conv1\"\n      top: \"pool1\"\n      pooling_param {\n        pool: MAX\n        kernel_size: 2\n        stride: 2\n      }\n    }\n    layer {\n      name: \"conv2\"\n      type: \"Convolution\"\n      bottom: \"pool1\"\n      top: \"conv2\"\n      param {\n        lr_mult: 1\n      }\n      param {\n        lr_mult: 2\n      }\n      convolution_param {\n        num_output: 50\n        kernel_size: 5\n        stride: 1\n        weight_filler {\n          type: \"xavier\"\n        }\n        bias_filler {\n          type: \"constant\"\n        }\n      }\n    }\n    layer {\n      name: \"pool2\"\n      type: \"Pooling\"\n      bottom: \"conv2\"\n      top: \"pool2\"\n      pooling_param {\n        pool: MAX\n        kernel_size: 2\n        stride: 2\n      }\n    }\n    layer {\n      name: \"fc1\"\n      type: \"InnerProduct\"\n      bottom: \"pool2\"\n      top: \"ip1\"\n      param {\n        lr_mult: 1\n      }\n      param {\n        lr_mult: 2\n      }\n      inner_product_param {\n        num_output: 500\n        weight_filler {\n          type: \"xavier\"\n        }\n        bias_filler {\n          type: \"constant\"\n        }\n      }\n    }\n    layer {\n      name: \"relu1\"\n      type: \"ReLU\"\n      bottom: \"ip1\"\n      top: \"ip1\"\n    }\n    layer {\n      name: \"ip2\"\n      type: \"InnerProduct\"\n      bottom: \"ip1\"\n      top: \"ip2\"\n      param {\n        lr_mult: 1\n      }\n      param {\n        lr_mult: 2\n      }\n      inner_product_param {\n        num_output: 2  #最后输出的分类数量，我这里是二分类，所以写２\n        weight_filler {\n          type: \"xavier\"\n        }\n        bias_filler {\n          type: \"constant\"\n        }\n      }\n    }\n    layer {\n      name: \"loss\"\n      type: \"Softmax\"\n      bottom: \"ip2\"\n      top: \"loss\"\n    }\n\n### **solver.prototxt**\n\n这个文件就是配置一下训练时的规则，这个文件里面的参数也是模型质量的关键。\n\n    net: \"/home/peter/桌面/caffe自定义数据集/make_model/train_val.prototxt\" #这里时train_val.prototxt文件的路径\n    test_iter: 8                # x * 50 = 训练集大小\n    test_interval: 50\n    base_lr: 0.01\n    lr_policy: \"step\"\n    gamma: 0.1\n    stepsize: 100\n    display: 20\n    max_iter: 100              #最大训练次数\n    momentum: 0.9\n    weight_decay: 0.0005\n    snapshot: 20                #每50次保存一次模型快照\n    snapshot_prefix: \"/home/peter/桌面/caffe自定义数据集/save_model/\" #生成快照的路径\n    solver_mode: CPU\n\n### **deploy.prototxt**\n\n这个文件是根据train\\_val.prototxt编写的，里面结构大体一样，只是把训练的参数去掉。\n这个文件我们只需要修改一处，将输出的类别改为2\n\n    name: \"LeNet\"\n    layer {\n      name: \"data\"\n      type: \"Input\"\n      top: \"data\"\n      input_param { shape: { dim: 1 dim: 3 dim: 20 dim: 20} }\n    }\n    layer {\n      name: \"conv1\"\n      type: \"Convolution\"\n      bottom: \"data\"\n      top: \"conv1\"\n      param {\n        lr_mult: 1\n      }\n      param {\n        lr_mult: 2\n      }\n      convolution_param {\n        num_output: 20\n        kernel_size: 5\n        stride: 1\n        weight_filler {\n          type: \"xavier\"\n        }\n        bias_filler {\n          type: \"constant\"\n        }\n      }\n    }\n    layer {\n      name: \"pool1\"\n      type: \"Pooling\"\n      bottom: \"conv1\"\n      top: \"pool1\"\n      pooling_param {\n        pool: MAX\n        kernel_size: 2\n        stride: 2\n      }\n    }\n    layer {\n      name: \"conv2\"\n      type: \"Convolution\"\n      bottom: \"pool1\"\n      top: \"conv2\"\n      param {\n        lr_mult: 1\n      }\n      param {\n        lr_mult: 2\n      }\n      convolution_param {\n        num_output: 50\n        kernel_size: 5\n        stride: 1\n        weight_filler {\n          type: \"xavier\"\n        }\n        bias_filler {\n          type: \"constant\"\n        }\n      }\n    }\n    layer {\n      name: \"pool2\"\n      type: \"Pooling\"\n      bottom: \"conv2\"\n      top: \"pool2\"\n      pooling_param {\n        pool: MAX\n        kernel_size: 2\n        stride: 2\n      }\n    }\n    layer {\n      name: \"fc1\"\n      type: \"InnerProduct\"\n      bottom: \"pool2\"\n      top: \"ip1\"\n      param {\n        lr_mult: 1\n      }\n      param {\n        lr_mult: 2\n      }\n      inner_product_param {\n        num_output: 500\n        weight_filler {\n          type: \"xavier\"\n        }\n        bias_filler {\n          type: \"constant\"\n        }\n      }\n    }\n    layer {\n      name: \"relu1\"\n      type: \"ReLU\"\n      bottom: \"ip1\"\n      top: \"ip1\"\n    }\n    layer {\n      name: \"ip2\"\n      type: \"InnerProduct\"\n      bottom: \"ip1\"\n      top: \"ip2\"\n      param {\n        lr_mult: 1\n      }\n      param {\n        lr_mult: 2\n      }\n      inner_product_param {\n        num_output: 2 #最后的分类数量\n        weight_filler {\n          type: \"xavier\"\n        }\n        bias_filler {\n          type: \"constant\"\n        }\n      }\n    }\n    layer {\n      name: \"loss\"\n      type: \"Softmax\"\n      bottom: \"ip2\"\n      top: \"loss\"\n    }\n\n至此，三个网络文件已经准备好了，下一步就是开始训练了．\n\n开始训练\n--------\n\n新建一个脚本来训练网络 `caffe_train.sh`\n\n    EXAMPLE=/home/peter/桌面/caffe自定义数据集 #工程的路径\n    caffe train --solver=$EXAMPLE/make_model/solver.prototxt\n    chmod -R 777 $EXAMPLE/save_model\n    echo \"完成\"\n\n如果你的路径填的都是对的，你会在工程目录的save\\_model文件夹下看到caffe训练出来的模型\n![image.png](https://i.loli.net/2019/12/14/p7dJQPgcslTxzuO.png)","tags":["Machine learning","Caffe"],"categories":["Machine learning","Caffe"]},{"title":"Spring Cloud 学习笔记","url":"/2020/Spring-Cloud-学习笔记/","content":"# Ⅰ、持久层\n\n\n## 一.ORM （关系型映射）框架 \n###  1.Mybatis\n* 插件：通用Mapper tk.mapper\n\n---\n\n### 2.Mybatis-Plus\n* 集成通用Mapper，不需要手动写CURD和分页功能\n\n---\n\n## 二、非关系型数据库\n### 1. Redis\n* Redis Desktop Manager\n\n---\n# Ⅱ、开发层\n\n## 一、服务器\n### 1.Tomcat\n### 2.Nginx\n\n* HTTP和反向代理web服务。负载均衡（服务器），请求转发\n\n---\n\n## 二、开发框架\n\n### 1.Spring\n\n### 2.SpringMVC\n\n### 3.Spring Boot\n\n---\n\n## 三、权限管理\n\n*  便捷的认证，授权，加密，会话管理\n\n### 1.Spring Security\n\n### 2.Shiro\n\n---\n\n## 四、容器\n\n### 1.Docker\n\n### 2.Kubernetesetes(k8s)\n\n*  自动化部署平台\n\n---\n\n# Ⅲ、服务层（SOA分布式服务）\n\n![图片.png](https://i.loli.net/2020/04/06/mQErsWDql6fFOng.png)\n\n\n## 一、注册中心\n\n### 1. Eurkea（已经停更）\n* 客户端：`@EnableEurekaClient`\n* 注册中心：`@EnableEurekaServer`\n  * 关闭自我保护机制：服务不可用时立刻删除：保证可用性（A）`enable-self-preservation: false`\n* 获得服务信息：\n\n```java\n@Resource\nprivate DiscoveryClient discoveryClient;//springcloud包下的\nList<String> services = discoveryClient.getServices();  //得到所有的微服务\nfor (String element : services) {\n\tlog.info(\"element:\" + element);\n}\nList<ServiceInstance> instances = discoveryClient.getInstances(\"CLOUD-PROVIDER-SERVICE\"); //得到一个具体微服务的所有实例\nfor (ServiceInstance instance : instances) {\n\tlog.info(instance.getServiceId() + \"\\t\" + instance.getHost() + \"\\t\" + instance.getPort() + \"\\t\" + instance.getUri());\n}\n```\n### 2. Zookeeper\n\n* 使用consul或者zookeeper作为注册中心时注册服务`@EnableDiscoveryClient`\n\n### 3. Consul\n\n* 在Linux服务器上运行`nohup ./consul agent -dev -http-port 8500 -client 0.0.0.0 &`\n\n---\n\n## 二、负载均衡\n\n### 1.Ribbon（已经停更）\n\n* 进程内LB（LoadBalance），软负载均衡。属于一个类库，不同于Nginx在服务器级别负载均衡。\n* Eureka默认引入Ribbon，不需要手动添加pom\n\n### 2. OpenFeign\n\n* 使用在消费端（Controller端）\n* 开启Feign`@EnableFeignClients`\n* 指定调用哪个微服务`@FeignClient(value = \"XXXXX\")`，在service接口上，需要在Controller端新建service接口使用注解\n\n---\n\n## 三、服务熔断、降级、限流\n\n> 服务变多，服务链路越来越长，一个服务不可用会导致“服务雪崩”，导致整个系统级联故障。需要服务降级来中断链路。\n\n* 服务降级：向调用方返回一个符合预期的、可处理的备选响应（FallBack），而不是长时间等待或抛出调用方法无法处理的异常\n  * 程序运行异常\n  * 程序运行超时\n  * 服务熔断触发服务降级\n  * 线程池满\n* 服务熔断：服务器达到最大访问量之后就会直接拒绝访问，使服务降级\n\n### 1.Hystrix（已经停更）\n\n* 开启Hystrix（主函数）`@EnableHystrix`\n\n* 服务降级\n\n  ```java\n  //在类上配置\n  @DefaultProperties(defaultFallback = \"fallcack方法名，可以写全类名\")\n  //在方法上配置\n  @HystrixCommand(fallbackMethod = \"降级方法名\", commandProperties = {\n      //设置这个线程的超时时间是3s，3s内是正常的业务逻辑，超过3s调用fallbackMethod指定的方法进行处理\n      @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"3000\")\n  })\n  ```\n\n  * 客户端配置：为Feign客户端定义的接口添加一个服务降级处理的实现类，在Feign接口上添加`@FeignClient(value = \"服务名\" ,fallback = fallcack方法名.class)`，然后写一个类实现服务接口，统一为接口的方法进行异常处理。（为类添加`@Component`注解让Spring识别到）\n\n* 服务熔断\n\n  ```java\n  @HystrixCommand(fallbackMethod = \"服务熔断方法名\", commandProperties = {\n      @HystrixProperty(name = \"circuitBreaker.enabled\", value = \"true\"),   //是否开启断路器\n      @HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\", value = \"10\"),  //请求次数\n      @HystrixProperty(name = \"circuitBreaker.sleepWindowInMilliseconds\", value = \"10000\"),    //时间窗口期\n      @HystrixProperty(name = \"circuitBreaker.errorThresholdPercentage\", value = \"60\"),    //失败率达到多少后跳闸\n  })\n  ```\n\n* 管理工具（HystrixDashboard）`@EnableHystrixDashboard`\n\n  * 需要在被监控端启动类上配置\n\n    ```java\n    /**\n         * 此配置是为了服务监控而配置，与服务容错本身无关,SpringCloud升级后的坑\n         * ServletRegistrationBean因为springboot的默认路径不是\"/hystrix.stream\"，\n         * 只要在自己的项目里配置上下面的servlet就可以了\n         */ \n    @Bean\n    public ServletRegistrationBean getServlet() {\n        HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet();\n        ServletRegistrationBean registrationBean = new ServletRegistrationBean(streamServlet);\n        registrationBean.setLoadOnStartup(1);\n        registrationBean.addUrlMappings(\"/hystrix.stream\");\n        registrationBean.setName(\"HystrixMetricsStreamServlet\");\n        return registrationBean;\n    }\n    ```\n\n---\n\n## 四、服务网关\n\n![图片.png](https://i.loli.net/2020/04/08/hdpiNkOs9zUGY3q.png)\n\n> 反向代理、鉴权、流量控制、熔断、日志监控\n\n### 1.zuul（已经停更）\n\n* 阻塞I/O开发，基于Servlet 2.5 ，不支持长连接（如WebSocket）\n\n### 2.Gateway\n\n* 异步非阻塞模型开发，建立在Spring Farmework 5、Project Reactor 和 Spring Boot 2 之上。支持长连接。\n* Route 路由：路由时构建网关的基本模块，它由ID，目标URI，一系列的断言和过滤器组成，如果断言为true则匹配该路由\n* Predicate 断言：开发人员可以匹配HTTP请求中的所有内容（例如请求头或请求参数），如果请求与断言相匹配则进行路由\n* Filter 过滤：在请求被路由前或者之后对请求进行修改\n\n---\n\n## 五、配置中心\n\n> 管理所有微服务的配置。.yml\n\n#### 1.Spring Cloud Config\n\n* 激活配置中心服务端`@EnableConfigServer`\n* 配置中心客户端`@EnableEurekaClient`\n\n---\n\n## 六、消息总线\n\n![image-20200409132047341](https://object-lealaxy.oss-cn-beijing.aliyuncs.com/img/image-20200409132047341.png)\n\n> 用轻量级消息代理来构建一个共用的消息主题，并让系统中所有微服务实例都连接上来。由于该主题中产生的消息会被所有实例监听和消费，所以成为消息总线。在总线上的各个实例，都可以方便地广播一些需要让其他连接在该主题上的实例都知道的消息。\n\n### 1.ActiveMQ\n\n### 2.RebbitMQ\n\n## 七、消息驱动\n\n### 1.Spring Cloud Stream\n> 屏蔽底层消息中间件差异，消息驱动微服务框架\n\n![image-20200409134502181](https://object-lealaxy.oss-cn-beijing.aliyuncs.com/img/image-20200409134502181.png)\n\n* 常用注解\n\n![常用注解](https://object-lealaxy.oss-cn-beijing.aliyuncs.com/img/image-20200409135302145.png)\n\n* 发送消息\n\n  * 配置\n\n    ```yml\n          bindings: # 服务的整合处理\n            output: # 这个名字是一个通道的名称\n              destination: studyExchange # 中间件中topic的名字\n              content-type: application/json # 设置消息类型，本次为json，文本则设为text/plain\n              binder: defaultRabbit # 设置要绑定的消息服务的具体设置\n    ```\n\n    \n\n  * 注解\n\n    ```java\n    //这不是传统的service,这是和rabbitmq打交道的，不需要加注解@Service\n    //这里不调用dao，调用消息中间件的service\n    //信道channel和exchange绑定在一起\n    @EnableBinding(Source.class)\n    public class MessageProviderImpl implements IMessageProvider {\n        /**\n         * 消息发送管道\n         */\n        @Resource\n        private MessageChannel output;\n    \n        @Override\n        public String send() {\n            String serial = UUID.randomUUID().toString();\n            output.send(MessageBuilder.withPayload(serial).build());\n            System.out.println(\"serial = \" + serial);\n            return serial;\n        }\n    }\n    ```\n\n* 接收消息\n\n  * 配置\n\n    ```yml\n          bindings: # 服务的整合处理\n            input: # 这个名字是一个通道的名称\n              destination: studyExchange # 中间件中topic的名字\n              content-type: application/json # 设置消息类型，本次为json，文本则设为text/plain\n              binder: defaultRabbit # 设置要绑定的消息服务的具体设置\n              group: testgroup #给消息分组，避免重复消费\n    ```\n\n  * Controller\n\n    ```java\n    @Component\n    @EnableBinding(Sink.class)\n    public class ReceiveMessageListenerController {\n    \n        @StreamListener(Sink.INPUT)\n        public void input(Message<String> message) {\n            System.out.println(\"接收到的消息： \" + message.getPayload());\n        }\n    }\n    ```\n\n## 八、分布式请求链路追踪\n\n### 1.Spring Cloud Sleuth\n\n* 一条链路通过Trace id 唯一标识，Span标识发起请求的信息，各Span通过parent id关联\n\n---\n\n# Ⅳ、方便的类库\n\n\n## Hutool\n\n* 项目中“util”包友好的替代，节省了开发人员对项目中公用类和公用工具方法的封装时间.\n\n* [官方文档](https://hutool.cn/docs/#/)\n\n* [官网](https://hutool.cn/)\n\n  \n---\n\n## Lombok\n\n* 通过简单的注解形式来帮助我们简化消除一些必须有但显得很臃肿的Java代码\n> 需要安装 idea+lombok插件\n\n```java\n@Data //自动生成 @ToString、@EqualsAndHashCode、@Getter @Setter和@RequiredArgsConstructor\n@AllArgsConstructor//生成一个全参数的构造方法\n@NoArgsConstructor//生成一个无参构造方法\n@Slf4j//自动生成logger。log.info(\"xxx\");\n```\n\n---\n\n## POI\n\n* 操作excel表格\n\n---\n\n## Echars\n\n*  百度开源的数据可视化工具，专门用来绘制各种图表\n\n---\n\n## Element UI\n\n*  饿了吗开源的前端构建框架\n\n---\n\n## Fastjson\n\n* 阿里开源的Json组件，快速进行Json to java bean\n\n---\n\n## Quartz\n\n* 定时任务组件\n\n---\n\n# Ⅴ、🔧工具\n\n\n## ElasticSearch\n\n*  倒排索引的搜索框架（B+树），用于进行全文搜索\n\n> 管理工具：kibana\n\n---\n\n## FastDFS\n\n*  阿里开源的分布式文件存储系统\n\n---\n\n## Postman\n\n*  便捷调试post请求\n\n---\n\n# Ⅵ、🏹IDEA 插件\n\n---\n\n## Translation\n\n* 翻译软件\n\n---\n\n## Statistic\n\n* 统计代码行数\n\n---\n\n## Rainbow Brackets\n\n*  彩虹色括号\n\n---\n\n## MyBatis Log Plugin\n\n* 在控制台打印并自动拼接SQL语句，查看给DB发送的最终SQL\n\n---\n\n## Free MyBatis Plugin\n\n* 生成mapper xml文件\n* 快速从代码跳转到mapper及从mapper返回代码\n* mybatis自动补全及语法错误提示\n* 集成mybatis generator gui界面\n---\n\n## JRebel and XRebel\n\n* 自动热部署工具，写JavaWEB就不需要每次改完代码重启服务器了\n> [安装教程](https://blog.csdn.net/qierkang/article/details/95095954)\n\n---\n\n## Alibaba Java Coding Guidelines\n\n* 阿里巴巴代码规范审核工具\n\n> 有一点过于严格了，其中有一些规则不想使用可以删掉","tags":["Java","Spring","Spring Cloud"],"categories":["Java","Spring","Spring Cloud"]}]